{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9DEOvsDDP_adult_LPCEO.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tIEkDw7fexa"
      },
      "source": [
        "# Import libraries necessary for this project\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "sns.set(style=\"darkgrid\")\n",
        "from time import time\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Import the three supervised learning models from sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA    \n",
        "\n",
        "# Pretty display for notebooks\n",
        "%matplotlib inline\n",
        "from random import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b4A2tdgUfeye",
        "outputId": "28069ca3-42c4-484b-a70b-59b9a1cfed39"
      },
      "source": [
        "# without accuracy\n",
        "import time\n",
        "# import pulp as p \n",
        "# from random import *\n",
        "\n",
        "# Add column names to data set\n",
        "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', \n",
        "           'relationship', 'race','sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
        "\n",
        "# Read in train data\n",
        "adult_train = pd.read_csv('data/adult_actual/adult_train_data.csv', header=None, names=columns, skipinitialspace=True)\n",
        "\n",
        "# Drop the fnlwgt column which is useless for later analysis\n",
        "adult_train = adult_train.drop('fnlwgt', axis=1)\n",
        "\n",
        "# Read in test data\n",
        "adult_test = pd.read_csv('data/adult_actual/adult_test_data.csv', header=None, skiprows=1, names=columns, skipinitialspace=True)\n",
        "\n",
        "# Drop the fnlwgt column which is useless for later analysis\n",
        "adult_test = adult_test.drop('fnlwgt', axis=1)\n",
        "\n",
        "# Remove '.' in income column\n",
        "adult_test['income'] = adult_test['income'].apply(lambda x: '>50k' if x=='>50k.'  else '<=50k')\n",
        "\n",
        "\n",
        "# Convert '?' to NaNs and remove the entries with NaN value\n",
        "# Check missing value code and convert to NaNs\n",
        "object_col = adult_train.select_dtypes(include=object).columns.tolist()\n",
        "for col in object_col:\n",
        "    adult_train.loc[adult_train[col]=='?', col] = np.nan\n",
        "    adult_test.loc[adult_test[col]=='?', col] = np.nan\n",
        "\n",
        "# Perform an mssing assessment in each column of the dataset.\n",
        "col_missing_pct = adult_train.isna().sum()/adult_train.shape[0]\n",
        "col_missing_pct.sort_values(ascending=False)\n",
        "\n",
        "# Remove data entries with missing value\n",
        "adult_train = adult_train.dropna(axis=0, how='any')\n",
        "adult_test = adult_test.dropna(axis=0, how='any')\n",
        "\n",
        "# Show the results of the split\n",
        "# print(\"After removing the missing value:\")\n",
        "# print(\"Training set has {} samples.\".format(adult_train.shape[0]))\n",
        "# print(\"Testing set has {} samples.\".format(adult_test.shape[0]))\n",
        "for col in object_col:\n",
        "    print(adult_train[col].value_counts(dropna=False)/adult_train.shape[0],'\\n')\n",
        "# print(adult_train.head())\n",
        "# print(adult_test.head())    \n",
        "\n",
        "adult_train.reset_index(drop=True, inplace=True)\n",
        "adult_test.reset_index(drop=True, inplace=True)\n",
        "p=adult_train.shape[0]\n",
        "q=adult_test.shape[0]\n",
        "# reducing dimensionality of some very sparse features\n",
        "for i in range(0,p):\n",
        "    if adult_train.loc[i,'native-country'] not in [\"united-states\"] :\n",
        "               adult_train.loc[i,\"native-country\"] = \"non-united-stated\"        \n",
        "    if adult_train.loc[i,\"education\"] in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
        "               adult_train.loc[i,\"education\"] = \"prim-middle-school\"\n",
        "    elif adult_train.loc[i,\"education\"] in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
        "               adult_train.loc[i,\"education\"] = \"high-school\"   \n",
        "    if adult_train.loc[i,'income'] in [\">50k\"] :\n",
        "               adult_train.loc[i,\"income\"] = 1 \n",
        "    else: \n",
        "               adult_train.loc[i,\"income\"] = 0         \n",
        "#reducing dimensionality of some very sparse features\n",
        "for i in range(0,q):                \n",
        "    if adult_test.loc[i,'native-country'] not in [\"united-states\"]:\n",
        "               adult_test.loc[i,'native-country'] = \"non-united-stated\"\n",
        "    if adult_test.loc[i,'education'] in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
        "               adult_test.loc[i,'education'] = \"prim-middle-school\"\n",
        "    elif adult_test.loc[i,'education'] in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
        "               adult_test.loc[i,'education'] = \"high-school\"   \n",
        "    if adult_test.loc[i,'income'] in [\">50k\",\">50k.\"] :\n",
        "               adult_test.loc[i,\"income\"] = 1 \n",
        "    else: \n",
        "               adult_test.loc[i,\"income\"] = 0            \n",
        "# print(adult_train.head())\n",
        "# print(adult_test.head())\n",
        "DATA=pd.concat([adult_train,adult_test],ignore_index=True)\n",
        "# print(DATA.tail())\n",
        "m=DATA.shape[1]\n",
        "\n",
        "dat=DATA.iloc[:,0:m-1]\n",
        "\n",
        "\n",
        "# Initialize a scaler, then apply it to the features\n",
        "scaler = MinMaxScaler() # default=(0, 1)\n",
        "num_col = dat.dtypes[dat.dtypes != 'object'].index\n",
        "features_log_minmax_transform = pd.DataFrame(data = dat)\n",
        "features_log_minmax_transform[num_col] = scaler.fit_transform(features_log_minmax_transform[num_col])\n",
        "\n",
        "display(features_log_minmax_transform.head())\n",
        "\n",
        "# sens=DATA[['sex','race']]\n",
        "\n",
        "Data_c = pd.get_dummies(features_log_minmax_transform, columns=['sex','race','workclass','education','marital-status','occupation','relationship','native-country'], prefix =['s','r','work','edu','ms','occ','rls','nc'])\n",
        "r=DATA.iloc[:,m-1]\n",
        "print(Data_c)\n",
        "print(DATA['income'].value_counts())\n",
        "\n",
        "\n",
        "DATA=pd.concat([adult_train,adult_test],ignore_index=True)\n",
        "# print(DATA.tail())\n",
        "m=DATA.shape[1]\n",
        "\n",
        "dat=DATA.iloc[:,0:m-1]\n",
        "\n",
        "\n",
        "# Initialize a scaler, then apply it to the features\n",
        "scaler = MinMaxScaler() # default=(0, 1)\n",
        "num_col = dat.dtypes[dat.dtypes != 'object'].index\n",
        "features_log_minmax_transform = pd.DataFrame(data = dat)\n",
        "features_log_minmax_transform[num_col] = scaler.fit_transform(features_log_minmax_transform[num_col])\n",
        "\n",
        "display(features_log_minmax_transform.head())\n",
        "\n",
        "# sens=DATA[['sex','race']]\n",
        "\n",
        "Data_c = pd.get_dummies(features_log_minmax_transform, columns=['sex','race','workclass','education','marital-status','occupation','relationship','native-country'], prefix =['s','r','work','edu','ms','occ','rls','nc'])\n",
        "r=DATA.iloc[:,m-1]\n",
        "print(Data_c)\n",
        "print(DATA['income'].value_counts())\n",
        "#marital\n",
        "#U=80, M=24928, S=11568, D=4612\n",
        "# m_3, m_0, m_1, m_2\n",
        "#age\n",
        "#>60 and <25= a_1\n",
        "#>=25and <=60 =a_2\n",
        "# print(data.head())\n",
        "# print(data.shape[0],data.shape[1])\n",
        "\n",
        "#sensitive columns name 0='age',2='marital'\n",
        "\n",
        "\n",
        "#X_test,Y_test_pred,Y_test,e = adult_svm(Data_c , r)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#marital\n",
        "#U=80, M=24928, S=11568, D=4612\n",
        "# m_3, m_0, m_1, m_2\n",
        "#age\n",
        "#>60 and <25= a_1\n",
        "#>=25and <=60 =a_2\n",
        "# print(data.head())\n",
        "# print(data.shape[0],data.shape[1])\n",
        "\n",
        "#sensitive columns name 0='age',2='marital'\n",
        "\n",
        "\n",
        "#X_test,Y_test_pred,Y_test,e = adult_svm(Data_c , r)\n",
        "\n",
        "#X_test.reset_index(drop=True, inplace=True)\n",
        "# Y_test_pred.reset_index()\n",
        "#Y_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# print(X_test)\n",
        "# print(Y_test_pred)\n",
        "# print(Y_test)\n",
        "#sens=X_test[['s_male', 's_female'  ,'r_white', 'r_black', 'r_asian-pac-islander','r_amer-indian-eskimo','r_other']]\n",
        "#sensitive = sens.T\n",
        "#accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)\n",
        "\n",
        "\n",
        "# "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "private             0.738877\n",
            "self-emp-not-inc    0.082853\n",
            "local-gov           0.068530\n",
            "state-gov           0.042404\n",
            "self-emp-inc        0.035608\n",
            "federal-gov         0.031265\n",
            "without-pay         0.000464\n",
            "Name: workclass, dtype: float64 \n",
            "\n",
            "hs-grad         0.326238\n",
            "some-college    0.221404\n",
            "bachelors       0.167230\n",
            "masters         0.053942\n",
            "assoc-voc       0.043333\n",
            "11th            0.034746\n",
            "assoc-acdm      0.033420\n",
            "10th            0.027187\n",
            "7th-8th         0.018467\n",
            "prof-school     0.017970\n",
            "9th             0.015085\n",
            "12th            0.012499\n",
            "doctorate       0.012433\n",
            "5th-6th         0.009548\n",
            "1st-4th         0.005006\n",
            "preschool       0.001492\n",
            "Name: education, dtype: float64 \n",
            "\n",
            "married-civ-spouse       0.466315\n",
            "never-married            0.322459\n",
            "divorced                 0.139712\n",
            "separated                0.031132\n",
            "widowed                  0.027419\n",
            "married-spouse-absent    0.012267\n",
            "married-af-spouse        0.000696\n",
            "Name: marital-status, dtype: float64 \n",
            "\n",
            "prof-specialty       0.133877\n",
            "craft-repair         0.133612\n",
            "exec-managerial      0.132352\n",
            "adm-clerical         0.123367\n",
            "sales                0.118825\n",
            "other-service        0.106492\n",
            "machine-op-inspct    0.065181\n",
            "transport-moving     0.052119\n",
            "handlers-cleaners    0.044758\n",
            "farming-fishing      0.032790\n",
            "tech-support         0.030237\n",
            "protective-serv      0.021351\n",
            "priv-house-serv      0.004741\n",
            "armed-forces         0.000298\n",
            "Name: occupation, dtype: float64 \n",
            "\n",
            "husband           0.413202\n",
            "not-in-family     0.256150\n",
            "own-child         0.148067\n",
            "unmarried         0.106492\n",
            "wife              0.046615\n",
            "other-relative    0.029474\n",
            "Name: relationship, dtype: float64 \n",
            "\n",
            "white                 0.859790\n",
            "black                 0.093396\n",
            "asian-pac-islander    0.029673\n",
            "amer-indian-eskimo    0.009482\n",
            "other                 0.007659\n",
            "Name: race, dtype: float64 \n",
            "\n",
            "male      0.675685\n",
            "female    0.324315\n",
            "Name: sex, dtype: float64 \n",
            "\n",
            "united-states                 0.911876\n",
            "mexico                        0.020224\n",
            "philippines                   0.006233\n",
            "germany                       0.004244\n",
            "puerto-rico                   0.003614\n",
            "canada                        0.003548\n",
            "india                         0.003315\n",
            "el-salvador                   0.003315\n",
            "cuba                          0.003050\n",
            "england                       0.002851\n",
            "jamaica                       0.002652\n",
            "south                         0.002354\n",
            "china                         0.002254\n",
            "italy                         0.002254\n",
            "dominican-republic            0.002221\n",
            "vietnam                       0.002122\n",
            "guatemala                     0.002089\n",
            "japan                         0.001956\n",
            "poland                        0.001857\n",
            "columbia                      0.001857\n",
            "haiti                         0.001392\n",
            "taiwan                        0.001392\n",
            "iran                          0.001392\n",
            "portugal                      0.001127\n",
            "nicaragua                     0.001094\n",
            "peru                          0.000995\n",
            "greece                        0.000961\n",
            "ecuador                       0.000895\n",
            "france                        0.000895\n",
            "ireland                       0.000796\n",
            "hong                          0.000630\n",
            "cambodia                      0.000597\n",
            "trinadad&tobago               0.000597\n",
            "laos                          0.000564\n",
            "thailand                      0.000564\n",
            "yugoslavia                    0.000530\n",
            "outlying-us(guam-usvi-etc)    0.000464\n",
            "hungary                       0.000431\n",
            "honduras                      0.000398\n",
            "scotland                      0.000365\n",
            "holand-netherlands            0.000033\n",
            "Name: native-country, dtype: float64 \n",
            "\n",
            "<=50k    0.751078\n",
            ">50k     0.248922\n",
            "Name: income, dtype: float64 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2e70b49f-c509-4b02-8db9-dace7cec0dea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.301370</td>\n",
              "      <td>state-gov</td>\n",
              "      <td>bachelors</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>never-married</td>\n",
              "      <td>adm-clerical</td>\n",
              "      <td>not-in-family</td>\n",
              "      <td>white</td>\n",
              "      <td>male</td>\n",
              "      <td>0.02174</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>united-states</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.452055</td>\n",
              "      <td>self-emp-not-inc</td>\n",
              "      <td>bachelors</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>married-civ-spouse</td>\n",
              "      <td>exec-managerial</td>\n",
              "      <td>husband</td>\n",
              "      <td>white</td>\n",
              "      <td>male</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122449</td>\n",
              "      <td>united-states</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.287671</td>\n",
              "      <td>private</td>\n",
              "      <td>hs-grad</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>divorced</td>\n",
              "      <td>handlers-cleaners</td>\n",
              "      <td>not-in-family</td>\n",
              "      <td>white</td>\n",
              "      <td>male</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>united-states</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.493151</td>\n",
              "      <td>private</td>\n",
              "      <td>high-school</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>married-civ-spouse</td>\n",
              "      <td>handlers-cleaners</td>\n",
              "      <td>husband</td>\n",
              "      <td>black</td>\n",
              "      <td>male</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>united-states</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.150685</td>\n",
              "      <td>private</td>\n",
              "      <td>bachelors</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>married-civ-spouse</td>\n",
              "      <td>prof-specialty</td>\n",
              "      <td>wife</td>\n",
              "      <td>black</td>\n",
              "      <td>female</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>non-united-stated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e70b49f-c509-4b02-8db9-dace7cec0dea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e70b49f-c509-4b02-8db9-dace7cec0dea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e70b49f-c509-4b02-8db9-dace7cec0dea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        age         workclass  ... hours-per-week     native-country\n",
              "0  0.301370         state-gov  ...       0.397959      united-states\n",
              "1  0.452055  self-emp-not-inc  ...       0.122449      united-states\n",
              "2  0.287671           private  ...       0.397959      united-states\n",
              "3  0.493151           private  ...       0.397959      united-states\n",
              "4  0.150685           private  ...       0.397959  non-united-stated\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            age  education-num  ...  nc_non-united-stated  nc_united-states\n",
            "0      0.301370       0.800000  ...                     0                 1\n",
            "1      0.452055       0.800000  ...                     0                 1\n",
            "2      0.287671       0.533333  ...                     0                 1\n",
            "3      0.493151       0.400000  ...                     0                 1\n",
            "4      0.150685       0.800000  ...                     1                 0\n",
            "...         ...            ...  ...                   ...               ...\n",
            "45216  0.219178       0.800000  ...                     0                 1\n",
            "45217  0.301370       0.800000  ...                     0                 1\n",
            "45218  0.287671       0.800000  ...                     0                 1\n",
            "45219  0.369863       0.800000  ...                     0                 1\n",
            "45220  0.246575       0.800000  ...                     0                 1\n",
            "\n",
            "[45221 rows x 59 columns]\n",
            "0    34013\n",
            "1    11208\n",
            "Name: income, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a707f7c9-082d-4464-a05c-ce31c95a55a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.301370</td>\n",
              "      <td>state-gov</td>\n",
              "      <td>bachelors</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>never-married</td>\n",
              "      <td>adm-clerical</td>\n",
              "      <td>not-in-family</td>\n",
              "      <td>white</td>\n",
              "      <td>male</td>\n",
              "      <td>0.02174</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>united-states</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.452055</td>\n",
              "      <td>self-emp-not-inc</td>\n",
              "      <td>bachelors</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>married-civ-spouse</td>\n",
              "      <td>exec-managerial</td>\n",
              "      <td>husband</td>\n",
              "      <td>white</td>\n",
              "      <td>male</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122449</td>\n",
              "      <td>united-states</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.287671</td>\n",
              "      <td>private</td>\n",
              "      <td>hs-grad</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>divorced</td>\n",
              "      <td>handlers-cleaners</td>\n",
              "      <td>not-in-family</td>\n",
              "      <td>white</td>\n",
              "      <td>male</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>united-states</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.493151</td>\n",
              "      <td>private</td>\n",
              "      <td>high-school</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>married-civ-spouse</td>\n",
              "      <td>handlers-cleaners</td>\n",
              "      <td>husband</td>\n",
              "      <td>black</td>\n",
              "      <td>male</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>united-states</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.150685</td>\n",
              "      <td>private</td>\n",
              "      <td>bachelors</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>married-civ-spouse</td>\n",
              "      <td>prof-specialty</td>\n",
              "      <td>wife</td>\n",
              "      <td>black</td>\n",
              "      <td>female</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>non-united-stated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a707f7c9-082d-4464-a05c-ce31c95a55a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a707f7c9-082d-4464-a05c-ce31c95a55a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a707f7c9-082d-4464-a05c-ce31c95a55a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        age         workclass  ... hours-per-week     native-country\n",
              "0  0.301370         state-gov  ...       0.397959      united-states\n",
              "1  0.452055  self-emp-not-inc  ...       0.122449      united-states\n",
              "2  0.287671           private  ...       0.397959      united-states\n",
              "3  0.493151           private  ...       0.397959      united-states\n",
              "4  0.150685           private  ...       0.397959  non-united-stated\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            age  education-num  ...  nc_non-united-stated  nc_united-states\n",
            "0      0.301370       0.800000  ...                     0                 1\n",
            "1      0.452055       0.800000  ...                     0                 1\n",
            "2      0.287671       0.533333  ...                     0                 1\n",
            "3      0.493151       0.400000  ...                     0                 1\n",
            "4      0.150685       0.800000  ...                     1                 0\n",
            "...         ...            ...  ...                   ...               ...\n",
            "45216  0.219178       0.800000  ...                     0                 1\n",
            "45217  0.301370       0.800000  ...                     0                 1\n",
            "45218  0.287671       0.800000  ...                     0                 1\n",
            "45219  0.369863       0.800000  ...                     0                 1\n",
            "45220  0.246575       0.800000  ...                     0                 1\n",
            "\n",
            "[45221 rows x 59 columns]\n",
            "0    34013\n",
            "1    11208\n",
            "Name: income, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMXXgARzfezB",
        "outputId": "d7c91531-54ec-4f9f-92e3-cc2b9d8585b3"
      },
      "source": [
        "#from aif360.datasets import AdultDataset\n",
        "from scipy.optimize import minimize\n",
        "from warnings import warn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.base import BaseEstimator, MetaEstimatorMixin, clone\n",
        "\n",
        "\n",
        "#ad = AdultDataset(instance_weights_name='fnlwgt',features_to_drop=[])\n",
        "#WARNING:root:Missing Data: 3620 rows removed from dataset.\n",
        "single_protected = ['sex','race']\n",
        "single_privileged = [['Male'],['White']]\n",
        "#ceo = CalibratedEqualizedOdds(prot_attr = None)\n",
        "y_train = adult_train.loc[:,'income']\n",
        "y_test = adult_test.loc[:,'income']\n",
        "adult_train_X = adult_train.drop('income', axis=1)\n",
        "adult_test_X = adult_test.drop('income', axis=1)\n",
        "\n",
        "print(list(set(y_train.index.names)))\n",
        "print(y_train.index.names)      \n",
        "print(len(adult_train.columns))\n",
        "print(len(adult_train_X.columns))\n",
        "\n",
        "\n",
        "X_train = adult_train_X\n",
        "X_test = adult_test_X\n",
        "X_train, X_test, y_train, y_test = train_test_split(Data_c , r, test_size= 0.3, random_state=0, shuffle=True)\n",
        "#data_preproc = make_column_transformer((OneHotEncoder(sparse=False, handle_unknown='ignore'),\n",
        "#                                        X_train.dtypes == 'category'), remainder=StandardScaler())\n",
        "\n",
        "#X_train = pd.DataFrame(data_preproc.fit_transform(X_train), index=X_train.index)\n",
        "#X_test = pd.DataFrame(data_preproc.fit_transform(X_test), index=X_test.index)\n",
        "\n",
        "y_train=y_train.astype('int')\n",
        "y_test=y_test.astype('int')\n",
        "print(y_train)\n",
        "y_train = y_train.rename_axis('race')\n",
        "print(y_train)\n",
        "print(X_train)\n",
        "l = []\n",
        "for i in range(len(y_train)):\n",
        "    if(X_train.iloc[i,9]==1):\n",
        "        l.append(0)\n",
        "    else:\n",
        "        l.append(1)\n",
        "\n",
        "y_train.index = l\n",
        "y_train = y_train.rename_axis('s_male')\n",
        "print(y_train)\n",
        "#print(p not in y_train.index.names for p in 'race')\n",
        "print(y_train.index.names)    \n",
        "\n",
        "data_preproc = make_column_transformer(\n",
        "    (OneHotEncoder(sparse=False, handle_unknown='ignore'), X_train.dtypes == 'category'),\n",
        "        remainder=StandardScaler())\n",
        "\n",
        "#X_train = pd.DataFrame(data_preproc.fit_transform(X_train), index=X_train.index)\n",
        "#X_test = pd.DataFrame(data_preproc.transform(X_test), index=X_test.index)\n",
        "\n",
        "lr = LogisticRegression()\n",
        "#pp = CalibratedEqualizedOdds(prot_attr='s_male',cost_constraint='weighted', random_state=1234567)\n",
        "#lr = LogisticRegression(C=1000.0, random_state=0)\n",
        "#ceo = PostProcessingMeta(estimator=lr,postprocessor=pp, random_state=1234567)\n",
        "#ceo.fit(X_train, y_train)\n",
        "#ceo.prot_attr_= '9'\n",
        "\n",
        "print(X_test)\n",
        "\n",
        "\n",
        "#ceo.fit(adult_train_X, y_train)\n",
        "#z = ceo.predict(adult_test)\n",
        "\n",
        "#ad_data = AdultDataset(protected_attribute_names=single_protected, privileged_classes=single_privileged, categorical_features=[],features_to_keep=['age', 'education-num'])\n",
        "#print(ad_data.df.size)\n",
        "#['education-num', 'age', 'sex'] \n",
        "#print(ad.label_names)\n",
        "#x,y = adv._classifier_model(ad_data.features_names, 3, 0.4)\n",
        "#op = OptimPreproc(rosen, {'disp': True}, unprivileged_groups=[{'sex':'Female'}], privileged_groups=[{'sex':'Male'}])\n",
        "#ad_data_new = op.fit_transform(ad_data)\n",
        "#['income-per-year']\n",
        "\n",
        "#origin_adult = BinaryLabelDataset(df = adult_test, label_names = 'income',\n",
        "#                                protected_attribute_names = ['sex', 'race'], \n",
        "#                                privileged_protected_attributes = ['Male','White'],\n",
        "#                                instance_weights_name=None,\n",
        "                               # categorical_features=['workclass', 'education','marital-status', 'occupation', 'relationship','native-country'],  \n",
        "                               # features_to_drop=['fnlwgt'],custom_preprocessing=None,\n",
        "#                                favorable_label='1', unfavorable_label='0')\n",
        "\n",
        "\n",
        "#svm_adult = BinaryLabelDataset()\n",
        "\n",
        "#ad2 = eo.fit(ad_data,ad_data_new)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None]\n",
            "[None]\n",
            "14\n",
            "13\n",
            "10300    0\n",
            "39301    1\n",
            "2666     0\n",
            "17989    0\n",
            "11495    0\n",
            "        ..\n",
            "30403    0\n",
            "21243    1\n",
            "42613    1\n",
            "43567    1\n",
            "2732     0\n",
            "Name: income, Length: 31654, dtype: int64\n",
            "race\n",
            "10300    0\n",
            "39301    1\n",
            "2666     0\n",
            "17989    0\n",
            "11495    0\n",
            "        ..\n",
            "30403    0\n",
            "21243    1\n",
            "42613    1\n",
            "43567    1\n",
            "2732     0\n",
            "Name: income, Length: 31654, dtype: int64\n",
            "            age  education-num  ...  nc_non-united-stated  nc_united-states\n",
            "10300  0.013699       0.400000  ...                     0                 1\n",
            "39301  0.328767       0.800000  ...                     0                 1\n",
            "2666   0.342466       0.600000  ...                     0                 1\n",
            "17989  0.041096       0.533333  ...                     0                 1\n",
            "11495  0.315068       0.600000  ...                     0                 1\n",
            "...         ...            ...  ...                   ...               ...\n",
            "30403  0.123288       0.800000  ...                     0                 1\n",
            "21243  0.301370       0.666667  ...                     0                 1\n",
            "42613  0.643836       0.533333  ...                     0                 1\n",
            "43567  0.424658       0.600000  ...                     0                 1\n",
            "2732   0.232877       0.533333  ...                     0                 1\n",
            "\n",
            "[31654 rows x 59 columns]\n",
            "s_male\n",
            "1    0\n",
            "1    1\n",
            "1    0\n",
            "1    0\n",
            "1    0\n",
            "    ..\n",
            "1    0\n",
            "1    1\n",
            "1    1\n",
            "0    1\n",
            "1    0\n",
            "Name: income, Length: 31654, dtype: int64\n",
            "['s_male']\n",
            "            age  education-num  ...  nc_non-united-stated  nc_united-states\n",
            "41386  0.082192       0.733333  ...                     1                 0\n",
            "35278  0.315068       0.600000  ...                     0                 1\n",
            "26950  0.301370       0.600000  ...                     0                 1\n",
            "29133  0.369863       0.400000  ...                     0                 1\n",
            "41793  0.191781       0.533333  ...                     0                 1\n",
            "...         ...            ...  ...                   ...               ...\n",
            "26337  0.232877       0.600000  ...                     0                 1\n",
            "12251  0.109589       0.600000  ...                     0                 1\n",
            "1411   0.438356       0.333333  ...                     0                 1\n",
            "10478  0.205479       0.533333  ...                     0                 1\n",
            "38459  0.000000       0.466667  ...                     0                 1\n",
            "\n",
            "[13567 rows x 59 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zrvOSXVfezi",
        "outputId": "e2614cd7-9d98-45a8-d615-79b812dba873"
      },
      "source": [
        " pip install pulp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pulp\n",
            "  Downloading PuLP-2.6.0-py3-none-any.whl (14.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.2 MB 23.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pulp\n",
            "Successfully installed pulp-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z94Un5T_fezp",
        "outputId": "b3c1f185-7f8c-401e-b993-43b3f4033641"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score  \n",
        "from sklearn.svm import SVC\n",
        "rf = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=64, random_state=0)\n",
        "#svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0,probability=True)\n",
        "rf.fit(X_train, y_train)\n",
        "print('The accuracy of the Random_Forest classifier on training data is {:.2f}'.format(rf.score(X_train, y_train)))\n",
        "print('The accuracy of the Random_Forest classifier on test data is {:.2f}'.format(rf.score(X_test, y_test)))\n",
        "print('####Train prediction Label###############################################')\n",
        "y_train_pred=rf.predict(X_train)\n",
        "#print(y_1)\n",
        "y_test_pred=rf.predict(X_test)\n",
        "e=rf.predict_proba(X_test)\n",
        "print(e)\n",
        "print(y_test_pred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the Random_Forest classifier on training data is 0.88\n",
            "The accuracy of the Random_Forest classifier on test data is 0.87\n",
            "####Train prediction Label###############################################\n",
            "[[0.69829171 0.30170829]\n",
            " [0.96621278 0.03378722]\n",
            " [0.85440665 0.14559335]\n",
            " ...\n",
            " [0.82390484 0.17609516]\n",
            " [0.99506751 0.00493249]\n",
            " [1.         0.        ]]\n",
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sv90ZmMLo_CQ",
        "outputId": "8622e1c8-3abe-493a-976e-a6832b63346d"
      },
      "source": [
        "sens=X_test[['s_male', 's_female'  ,'r_white', 'r_black', 'r_asian-pac-islander','r_amer-indian-eskimo','r_other']]\n",
        "sens_train_race= X_train[['r_white', 'r_black', 'r_asian-pac-islander','r_amer-indian-eskimo','r_other']]\n",
        "sens_train = X_train[['s_male', 's_female'  ,'r_white', 'r_black', 'r_asian-pac-islander','r_amer-indian-eskimo','r_other']]\n",
        "sens_train_sex = X_train[['s_male', 's_female']]\n",
        "\n",
        "sens_test_race = X_test[['r_white', 'r_black', 'r_asian-pac-islander','r_amer-indian-eskimo','r_other']]\n",
        "sens_test_sex = X_test[['s_male', 's_female']]\n",
        "\n",
        "print(sens)\n",
        "sensitive = sens.T\n",
        "#print(sensitive_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       s_male  s_female  ...  r_amer-indian-eskimo  r_other\n",
            "41386       0         1  ...                     0        0\n",
            "35278       0         1  ...                     0        0\n",
            "26950       1         0  ...                     0        0\n",
            "29133       0         1  ...                     0        0\n",
            "41793       1         0  ...                     0        0\n",
            "...       ...       ...  ...                   ...      ...\n",
            "26337       1         0  ...                     0        0\n",
            "12251       0         1  ...                     0        0\n",
            "1411        1         0  ...                     0        0\n",
            "10478       0         1  ...                     0        0\n",
            "38459       0         1  ...                     0        0\n",
            "\n",
            "[13567 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14RjNrNUfe0A"
      },
      "source": [
        "from random import *\n",
        "beta_natural=[0.2576267506242536, 0.07575757575757576, 0.2111662955985614, 0.08934426229508197, 0.2698019801980198, 0.1, 0.034782608695652174]\n",
        "\n",
        "def find_eo_stats_multiple(y,y_pred):    \n",
        "    m = 7\n",
        "    sens_stats = np.zeros((4,m), dtype = int)\n",
        "    sens_acc = np.zeros(m, dtype = float)\n",
        "    sizes = np.zeros(m, dtype = int)\n",
        "    #first row positives, second row negatives, third row true positive, fourth row false positive\n",
        "    \n",
        "    \n",
        "    for i in range(m):\n",
        "        for j in range(len(y)):\n",
        "            if(sensitive.iloc[i,j] == 1):\n",
        "                sizes[i] = sizes[i]+1\n",
        "                if(y_pred[j]==1):\n",
        "                    sens_acc[i] = sens_acc[i] + 1\n",
        "                if(y.iloc[j]==1):\n",
        "                    sens_stats[0][i] =sens_stats[0][i] + 1\n",
        "                if(y.iloc[j]==1 and y_pred[j]==1):\n",
        "                    sens_stats[2][i] =sens_stats[2][i] + 1\n",
        "                if(y.iloc[j]==0):\n",
        "                    sens_stats[1][i] =sens_stats[1][i] + 1\n",
        "                if(y.iloc[j]==0 and y_pred[j]==1):\n",
        "                    sens_stats[3][i] =sens_stats[3][i] + 1    \n",
        "        sens_acc[i] = sens_acc[i]/sizes[i]\n",
        "        #print(sens_acc[i],sizes[i])\n",
        "        \n",
        "    \n",
        "    TPR = np.zeros(m,dtype=float)\n",
        "    FPR = np.zeros(m,dtype=float)\n",
        "    precision = np.zeros(m,dtype=float)\n",
        "    \n",
        "    accu = 0\n",
        "    n = len(y)\n",
        "    #flip(y_pred)\n",
        "    for i in range(n):\n",
        "        if(y.iloc[i] == y_pred[i]):\n",
        "            accu = accu+1\n",
        "    \n",
        "    accu = accu/n\n",
        "    \n",
        "    max_tpr = -1 \n",
        "    min_tpr = 2\n",
        "    max_fpr = -1\n",
        "    min_fpr = 2\n",
        "    \n",
        "    for i in range(m):\n",
        "        TPR[i] = sens_stats[2][i]/sens_stats[0][i]\n",
        "        FPR[i] = sens_stats[3][i]/sens_stats[1][i]\n",
        "        if(TPR[i] >= max_tpr):\n",
        "            max_tpr = TPR[i]\n",
        "        if(TPR[i] <= min_tpr):\n",
        "            min_tpr = TPR[i]\n",
        "        if(FPR[i] >= max_fpr):\n",
        "            max_fpr = FPR[i]\n",
        "        if(FPR[i] <= min_fpr):\n",
        "            min_fpr = FPR[i]\n",
        "    \n",
        "    for i in  range(m):\n",
        "        print(\"TPR / Recall of the \",i,\"th sensitive groups is\",TPR[i])\n",
        "        \n",
        "    print(\"=====================\")    \n",
        "    for i in  range(m):\n",
        "        print(\"FPR of the \",i,\"th sensitive groups is\",FPR[i])\n",
        "    \n",
        "    print(\"=====================\")\n",
        "    for i in  range(m):    \n",
        "        print(\"Acceptance Rate of the \",i,\"th sensitive groups is\",sens_acc[i])\n",
        "    for i in range(m):\n",
        "        precision[i]=sens_stats[2][i]/(sens_acc[i]*sizes[i])\n",
        "        print(\"Precision of the \",i,\"th sensitive groups is\",precision[i])\n",
        "    DEO = abs(max_tpr-min_tpr) + abs(max_fpr-min_fpr)\n",
        "    \n",
        "\n",
        "       \n",
        "    weight_p=0\n",
        "    weight_r=0\n",
        "    weight_prec=0\n",
        "    weight_rec=0\n",
        "\n",
        "\n",
        "    weight_p_ng=0\n",
        "    weight_r_ng=0\n",
        "    weight_prec_ng=0\n",
        "    weight_rec_ng=0\n",
        "\n",
        "    for j in range(m):    \n",
        "        weight_prec=weight_prec+sizes[j]*precision[j]\n",
        "        weight_p=weight_p+sizes[j]\n",
        "        weight_rec=weight_rec+sizes[j]*TPR[j]\n",
        "        weight_r=weight_r+sizes[j] \n",
        "\n",
        "\n",
        "   # for j in range(m):    \n",
        "   #   if sens_acc[j] <= beta_natural[j]:\n",
        "   #     weight_prec_ng=weight_prec_ng +sizes[j]*precision[j]\n",
        "   #     weight_p_ng =weight_p_ng +sizes[j]\n",
        "   #   else:  \n",
        "   #     weight_rec_ng =weight_rec_ng +sizes[j]*TPR[j]\n",
        "   #     weight_r_ng =weight_r_ng +sizes[j] \n",
        "\n",
        "\n",
        "    wp=weight_prec/weight_p\n",
        "    wr=weight_rec/weight_r           \n",
        "    print(\"weighted prec,weighted rec\", wp,wr)\n",
        "    print(\"The TPR differnce is \", abs(max_tpr-min_tpr),\"The FPR difference is \", abs(max_fpr-min_fpr))   \n",
        "    print(\"The Difference of Equalized odds of the classifier is=\",DEO)\n",
        "    print(\"Accuracy of the classifier\",accu)\n",
        "         \n",
        "   \n",
        "    \n",
        "#find_eo_stats_multiple(y_test,y_pred_CEO)\n",
        "#find_eo_stats_multiple(y_test,y_test_pred)\n",
        "\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIhYlkKIyq6-",
        "outputId": "50f1bcbf-0f71-43ad-ee88-a62a81985ebc"
      },
      "source": [
        "pip install pulp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pulp in /usr/local/lib/python3.7/dist-packages (2.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUAbOcIufe0d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bilal - am_ind asian black other white female male(actual precision sequence)\n",
        "# 6         5          4          2                1              0                  3\n",
        "\n",
        "# ours -s_male, s_female  r_white, r_black, r_asian-pac-islander','r_amer-indian-eskimo','r_other\n",
        "           \n",
        "# beta=[6         5          4          2                1              0                  3]\n",
        "\n",
        "# beta=[beta[6], beta[5],beta[4],beta[2],beta[1],beta[0],beta[3]]\n",
        "\n",
        "\n",
        "#bilal -female male  am_ind asian  black other white (actual acceptance rate sequence)\n",
        "#          0      1     2       3     4      5    6   \n",
        "# ours -s_male, s_female  r_white, r_black, r_asian-pac-islander','r_amer-indian-eskimo', 'r_other\n",
        "           \n",
        "# beta=[1       0        6          4            3                   2                    5]\n",
        "\n",
        "\n",
        "#NG\n",
        "import time\n",
        "#import gurobipy as gp\n",
        "#from gurobipy import GRB\n",
        "import pulp as p \n",
        "def lp_equalized_odds(data1,eps,y_test_pred,e,beta_avg,alpha):\n",
        "    import pulp as p \n",
        "    import math\n",
        "    \n",
        "    \n",
        "    m=data1.shape[0]\n",
        "    n=data1.shape[1]\n",
        "    print('dimension of data')\n",
        "    print(m,n)\n",
        "    \n",
        "        \n",
        "    ############### #  SORTED for ACCURACY ONLY ####\n",
        "    m=7\n",
        "    h1=[]\n",
        "    key1=[]\n",
        "    cost=np.zeros(n,dtype=int)\n",
        "    data2=np.zeros((m,n),dtype=int)\n",
        "    \n",
        "    for i in range(n):\n",
        "            h1.append(e[i][1])\n",
        "            key1.append(i)\n",
        "\n",
        "        \n",
        "#print(hc)\n",
        "#     print(key1)\n",
        "    \n",
        "    for i in range(1,len(h1)):\n",
        "        for j in range(i,0,-1):\n",
        "            var=0\n",
        "            var2=0\n",
        "            if h1[j-1]<h1[j]:\n",
        "                index=j\n",
        "                var=h1[j]\n",
        "                h1[j]=h1[j-1]\n",
        "                h1[j-1]=var\n",
        "\n",
        "                var2=key1[j]\n",
        "                key1[j]=key1[j-1]\n",
        "                key1[j-1]=var2\n",
        "            else:\n",
        "                break\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    for j in range(len(key1)):    \n",
        "         data2[0][key1[j]]=j+1\n",
        "    \n",
        "    for j in range(n):\n",
        "        summ=0\n",
        "        summ=summ+data2[0][j] \n",
        "        cost[j]=summ\n",
        "\n",
        "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
        "    solver = p.getSolver('PULP_CBC_CMD', timeLimit=20)\n",
        "   \n",
        "    \n",
        "#     X=np.zeros(n+1,dtype=p.LpVariable)\n",
        "    X=np.zeros(n+m+1,dtype=p.LpVariable)\n",
        "    Y=np.zeros(m,dtype=p.LpVariable)\n",
        "    \n",
        "    sizes=np.zeros(m,dtype=int)\n",
        "#     report_index(index,data1,e):  \n",
        "    max_size=0\n",
        "    for i in range(m):\n",
        "        count=0\n",
        "        for j in range(n):\n",
        "            if data1[i][j]==1:\n",
        "                count=count+1 \n",
        "        if count>max_size:\n",
        "            max_size=count\n",
        "        sizes[i]=count\n",
        "    print(sizes)    \n",
        "    #############################33\n",
        "    \n",
        "    \n",
        "    \n",
        "    beta_actual = np.zeros(m,dtype=float)\n",
        "    ###############################\n",
        "    for i in range(m):\n",
        "      beta_actual[i] = eps\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    select_sizes=np.zeros(m,dtype=int)\n",
        "   \n",
        "    size_final=np.zeros(m,dtype=int)\n",
        "\n",
        "    for i in range(m):\n",
        "        var1 = str(n+100+i)\n",
        "        Y[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Continuous')\n",
        "    \n",
        "    for i in range(n):\n",
        "        var1=str(i)       \n",
        "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
        "   \n",
        "    X[n]=p.LpVariable(str(n),lowBound=0,upBound=1,cat='Continuous')  \n",
        "\n",
        "    tpr = p.LpVariable(str(n+200),lowBound=0,upBound=1,cat='Continuous')  \n",
        "    fpr = p.LpVariable(str(n+201),lowBound=0,upBound=1,cat='Continuous')  \n",
        "\n",
        "#     for i in range(m):\n",
        "#         k=n+i+1\n",
        "#         var1=str(k)     \n",
        "#         alpha=(((sizes[i])*(sizes[i]+1))/2)\n",
        "#         X[i]=p.LpVariable(var1,lowBound=(((beta*sizes[i])*(beta*sizes[i]+1))/2),upBound=alpha,cat='Continuous')\n",
        "    \n",
        "        \n",
        "#     X[n]=  p.LpVariable(\"z1\",lowBound=0)\n",
        "    #X[n+1]=  p.LpVariable(\"z2\",lowBound=0)\n",
        "  \n",
        "\n",
        "    #########objective function#####################\n",
        "    \n",
        "#     Lp_prob += 2*X[n+1]+10*X[n+2]+9*X[n+3]+3*X[n+4]\n",
        "    #alpha=0.8\n",
        "    #beta_avg = 0.10\n",
        "    Lp_prob+= p.lpSum([(X[j])*cost[j] for j in range(n)]) \n",
        "    #Lp_prob+=1  \n",
        "    \n",
        "    #Lp_prob += Y[0]*sizes[0] + Y[1]*sizes[1] >= p.lpSum([Y[j]*sizes[j] for j in np.arange(2,6)])\n",
        "    #Lp_prob += Y[0]*sizes[0] + Y[1]*sizes[1] <= p.lpSum([Y[j]*sizes[j] for j in np.arange(2,6)])\n",
        "    \n",
        "    ##############constraint#################\n",
        "    #first select the  the number of make female in test data\n",
        "    #then apply the equalized odd constraints assuming \n",
        "    #look at all males which have been predicted positve/and all the females predicted negative\n",
        "    F_test = 0\n",
        "    M_test = 0\n",
        "        \n",
        "    #for i in range(len(y_test)):\n",
        "    #    if(data1[0][i]==1 and y_test.iloc[i]==1):\n",
        "    #        M_test= M_test+1\n",
        "    #    elif(data1[1][i]==1 and y_test.iloc[i]==1):\n",
        "    #        F_test= F_test+1\n",
        "    test_count = np.zeros(m, dtype = int)\n",
        "\n",
        "    for i in range(len(y_test)):\n",
        "      for j in range(m): \n",
        "        if(data1[j][i]==1 and y_test_pred[i]==1):\n",
        "            test_count[j] = test_count[j] +1\n",
        "                \n",
        "    \n",
        "    #Lp_prob += (p.lpSum([(X[j])*(data1[0][j])*y_test_pred[j] for j in range(n) if y_test_pred[j]==1])/M_test) <= (p.lpSum([(X[j])*(data1[1][j])*y_test_pred[j] for j in range(n) if y_test_pred[j]==1])/F_test) + 0.0009\n",
        "    #Lp_prob += (p.lpSum([(X[j])*(data1[0][j])*(1-y_test_pred[j]) for j in range(n) if y_test_pred[j]==0])/(sizes[0]-M_test)) <= (p.lpSum([(X[j])*(data1[1][j])*(1-y_test_pred[j]) for j in range(n) if y_test_pred[j]==0])/(sizes[1]-F_test))+ 0.0009\n",
        "    for i in range(m):   #TPR constraints\n",
        "      Lp_prob += (1/test_count[i])*p.lpSum([(X[j])*(data1[i][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1) ]) >= tpr \n",
        "      Lp_prob += (1/test_count[i])*p.lpSum([(X[j])*(data1[i][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1 )]) <= tpr + 0.4\n",
        "    for i in range(m):    #FPR constraints\n",
        "      Lp_prob += (1/(sizes[i]-test_count[i]))*p.lpSum([(X[j])*(data1[i][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0)]) >= fpr\n",
        "      Lp_prob += (1/(sizes[i]-test_count[i]))*p.lpSum([(X[j])*(data1[i][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0)]) <= fpr + 0.2\n",
        "\n",
        "    #Lp_prob += F_test*p.lpSum([(X[j])*(data1[0][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1) ]) <= M_test*p.lpSum([(X[j])*(data1[1][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1 )]) + 0.004\n",
        "    #Lp_prob += (sizes[1]-F_test)*p.lpSum([(X[j])*(data1[0][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0)]) <= (sizes[0]-M_test)*p.lpSum([(X[j])*(data1[1][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0 )]) + 0.004\n",
        "    \n",
        "\n",
        "\n",
        "    #Lp_prob += F_test*p.lpSum([(X[j])*(data1[0][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1 and y_test.iloc[j]==1) ]) <= M_test*p.lpSum([(X[j])*(data1[1][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1 and y_test.iloc[j]==1)]) + 0.01\n",
        "    #Lp_prob += (sizes[1]-F_test)*p.lpSum([(X[j])*(data1[0][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0 and y_test.iloc[j]==0)]) <= (sizes[0]-M_test)*p.lpSum([(X[j])*(data1[1][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0 and y_test.iloc[j]==0)]) + 0.01\n",
        "    \n",
        "    #Lp_prob += p.lpSum([(X[j])*(data1[0][j])*y_test.iloc[j] for j in range(n) if y_test.iloc[j]==1])/M_test <= p.lpSum([(X[j])*(data1[1][j])*y_test.iloc[j] for j in range(n) if y_test.iloc[j]==1])/F_test + 0.004\n",
        "    #Lp_prob += (sizes[1]-F_test)*p.lpSum([(X[j])*(data1[0][j])*(1-y_test.iloc[j]) for j in range(n) if y_test.iloc[j]==0])/M_test <= (sizes[0]-M_test)*p.lpSum([(X[j])*(data1[1][j])*(1-y_test.iloc[j]) for j in range(n) if y_test.iloc[j]==0])/F_test + 0.004\n",
        "    \n",
        "    for i in range(m):\n",
        "      #  if i<m:\n",
        "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) >= Y[i]*sizes[i]\n",
        "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) <= (Y[i]+0.5)*sizes[i]\n",
        "    \n",
        "    for i in range(m):\n",
        "        if beta_actual[i] >= beta_avg:\n",
        "            Lp_prob += Y[i] >= (1-alpha)*beta_actual[i] + alpha*beta_avg\n",
        "            Lp_prob += Y[i] <= beta_actual[i]\n",
        "        else:\n",
        "            Lp_prob += Y[i] >= (1-alpha)*beta_actual[i] + alpha*beta_avg\n",
        "            Lp_prob += Y[i] <= beta_avg \n",
        "    \n",
        "           \n",
        "    #Lp_prob+= p.lpSum([(X[j])*cost[j] for j in range(n)])>=100\n",
        "        \n",
        "    #####################################\n",
        "    #solver = p.CPLEX_PY()\n",
        "    #solver.buildSolverModel(Lp_prob)\n",
        "    #Lp_prob.solverModel.parameters.timelimit.set(60)\n",
        "    #solver.callSolver(P)\n",
        "    #status = solver.findSolutionValues(Lp_prob)\n",
        "    #################################################################\n",
        "    status = Lp_prob.solve(solver)   # Solver \n",
        "    print(p.LpStatus[status]) \n",
        "    print(\"objective is:\")        \n",
        "    print(p.value(Lp_prob.objective))\n",
        "    print(\"discripency is:\") \n",
        "    print(p.value(X[n]))\n",
        "    x=np.zeros(n,dtype=float)\n",
        "\n",
        "   # The solution status \n",
        "    Synth1={}\n",
        "    Synth2={}\n",
        "    # # Printing the final solution \n",
        "    for i in range(n):\n",
        "        if(p.value(X[i])==1):\n",
        "            Synth1[i]=1 \n",
        "            Synth2[i]=-1\n",
        "#             if(data1[2][i]==1):\n",
        "#                 print(\"no\")\n",
        "        else:\n",
        "            Synth1[i]=-1\n",
        "            Synth2[i]=1\n",
        "    Synthu1=Synth1  \n",
        "    Synthu2=Synth2  \n",
        "    \n",
        "              \n",
        "    return Synthu1,Synthu2   \n"
      ],
      "metadata": {
        "id": "FIvyfnUdOUQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from scipy.signal import savgol_filter\n",
        "np.set_printoptions(precision=4)\n",
        "plt.style.use('seaborn-white')\n",
        "fig = plt.figure()\n",
        "ax = plt.subplot(111)\n",
        "\n",
        "\n",
        "eo =[0, 0.3437171786154355, 0.3918670501289364, 0.37119836083203195, 0.28430445597242165, 0.23488257013436864, 0.18473485176524929, 0.16879829469757524, 0.13665309892901478, 0.10684785504929384, 0] \n",
        "tpr =[0, 0.30244671875573165, 0.2994505494505495, 0.24725274725274726, 0.16086691086691085, 0.10317460317460314, 0.06666666666666665, 0.06666666666666665, 0.06666666666666665, 0.06666666666666665, 0] \n",
        "fpr =[0, 0.041270459859703824, 0.09241650067838689, 0.12394561357928466, 0.1234375451055108, 0.1317079669597655, 0.11806818509858263, 0.10213162803090858, 0.06998643226234813, 0.040181188382627187, 0]\n",
        "beta = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
        "\n",
        "ax.plot(beta,eo,label='Difference of EO',color='red',marker='^',linestyle='--') \n",
        "ax.plot(beta,tpr,label='Difference of TPR',color='blue',marker='^',linestyle='--')  \n",
        "ax.plot(beta,fpr,label='Difference of FPR',color='cyan',marker='^',linestyle='--') \n",
        "\n",
        "plt.title('')\n",
        "ax.set_xlabel('Acceptance Rate(beta)')\n",
        "ax.set_ylabel('DEO') \n",
        "# ax.set_ylabel('% in +ve class (Acceptance Rate)') \n",
        "\n",
        "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.30), shadow=True, ncol=10)\n",
        "plt.show() \n",
        "fig.savefig('a2.png') \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuodMYmnKWLz",
        "outputId": "90c8d3be-186b-4846-f2a4-7f299caf925e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vKZgklQ9KWPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3KSECGhiKWTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QM1pLg_WOUbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ht4wNL1NOUoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1Twwdewfe0y",
        "outputId": "c4a137f9-0dbd-4ed2-93b7-eb8d54146c99"
      },
      "source": [
        "pip install pulp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pulp\n",
            "  Downloading PuLP-2.5.1-py3-none-any.whl (41.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 41.2 MB 76 kB/s \n",
            "\u001b[?25hInstalling collected packages: pulp\n",
            "Successfully installed pulp-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spvW20mEfe2L"
      },
      "source": [
        "#without accuracy ---> 2\n",
        "def main2(datax, y_test, y_test_pred,e): \n",
        "      \n",
        "    n=datax.shape[1]\n",
        "    s=datax.shape[0]    \n",
        "    data = np.zeros((s, n), dtype = int)\n",
        "    \n",
        "    r = np.zeros(n, dtype = int) \n",
        "    \n",
        "    for i in range(n):\n",
        "        if int(y_test.iloc[i])==1 :\n",
        "            r[i]=1\n",
        "        else :\n",
        "            r[i]= -1  \n",
        "    \n",
        "    r2 = np.zeros(n, dtype = int) \n",
        "    for i in range(n):\n",
        "        if int(y_test_pred[i])==1 :\n",
        "            r2[i]=1\n",
        "        else :\n",
        "            r2[i]= -1          \n",
        "    ar=[]\n",
        "    \n",
        "    for j in range(s):\n",
        "        print(\"sensitive attribute \",(j+1)) \n",
        "        a=0\n",
        "        b=0\n",
        "        acc1=0\n",
        "        acc2=0\n",
        "        for i in range(n):\n",
        "                data[j][i]= datax.iloc[j,i]\n",
        "                if data[j][i]== 1 :\n",
        "                    a=a+1\n",
        "                    if r[i]==1:\n",
        "                         acc1=acc1+1 \n",
        "\n",
        "        print(\"ACTUAL----------total ,accepted, aceeptance rate:\")             \n",
        "        a1=float(acc1/a)\n",
        "        print(a)\n",
        "        \n",
        "        print(acc1)\n",
        "        print(a1)\n",
        "        ar.append(a1)\n",
        "        \n",
        "    maxi= max(ar)\n",
        "    mini= min(ar)\n",
        "    DP=float(maxi-mini)\n",
        "    print(\"data acceptance rates\")\n",
        "    print(ar)\n",
        "    print(\"data DP\")\n",
        "    print(DP)\n",
        "    \n",
        "    ar=[]\n",
        "    \n",
        "    for j in range(s):\n",
        "        print(\"sensitive attribute \",(j+1)) \n",
        "        a=0\n",
        "        b=0\n",
        "        acc1=0\n",
        "        acc2=0\n",
        "        prec=0\n",
        "        reca=0\n",
        "        accur=0\n",
        "        FP=0\n",
        "        FN=0\n",
        "        TP=0\n",
        "        TN=0\n",
        "        for i in range(n):\n",
        "             if data[j][i]== 1 :\n",
        "                    a=a+1\n",
        "                    if r2[i]==1:\n",
        "                        acc1=acc1+1 \n",
        "                        if r[i]==1:\n",
        "                            TP=TP+1\n",
        "                        else:\n",
        "                             FP=FP+1                \n",
        "                    else:\n",
        "                        if r[i]==1:\n",
        "                            FN=FN+1\n",
        "                        else:\n",
        "                            TN=TN+1    \n",
        "        \n",
        "        print(\"prec reca accuracy for each sens\") \n",
        "        prec= float(TP/(TP+FP))\n",
        "        reca= float(TP/(TP+FN))\n",
        "        accur= float((TP+TN)/a)\n",
        "        print(prec,reca,accur)\n",
        "        \n",
        "        print(\"SVM----------total , accepted, aceeptance rate:\")             \n",
        "        \n",
        "        a1=float(acc1/a)\n",
        "        print(a)\n",
        "        \n",
        "        print(acc1)\n",
        "        print(a1)\n",
        "        ar.append(a1)\n",
        "        \n",
        "    maxi= max(ar)\n",
        "    mini= min(ar)\n",
        "    DP=float(maxi-mini)\n",
        "    print(\"data acceptance rates\")\n",
        "    print(ar)\n",
        "    print(\"data DP\")\n",
        "    print(DP) \n",
        "    \n",
        "    print(\"SVM accuracy--------------------------\")\n",
        "    prec=0\n",
        "    reca=0\n",
        "    accur=0\n",
        "    FP=0\n",
        "    FN=0\n",
        "    TP=0\n",
        "    TN=0\n",
        "    for i in range(n):\n",
        "            if r2[i]==1:\n",
        "                acc1=acc1+1 \n",
        "                if r[i]==1:\n",
        "                    TP=TP+1\n",
        "                else:\n",
        "                     FP=FP+1                \n",
        "            else:\n",
        "                if r[i]==1:\n",
        "                     FN=FN+1\n",
        "                else:\n",
        "                     TN=TN+1    \n",
        "\n",
        "        \n",
        "    prec= float(TP/(TP+FP))\n",
        "    reca= float(TP/(TP+FN))\n",
        "    accur= float((TP+TN)/n)\n",
        "    print(prec,reca,accur)\n",
        "    \n",
        "    \n",
        "#     delta1=[.70,.75,.80,.85,.90,.95]\n",
        "    #gamma=.05,.06,.07\n",
        "    #delta1=[.80,.85,.90,.95]\n",
        "# (for reproducibility)  \n",
        "\n",
        "# delta1=[.8], gama=[.1], epsilon=[.05]  \n",
        "# delta1=[.8], gama=[.15], epsilon=[.01]\n",
        " \n",
        "#     delta1=np.arange(1,.79,-.01)\n",
        "    delta=1\n",
        "#     gama=[.05,.1,.15,.2,.25]\n",
        "#     epsilon=[.01,.02,.05,.1,.15,.20,.25,.30,.35,.40,.50]\n",
        "\n",
        "#ADULT ZAFAR =? epsilon=[0.088 ,0.1656, 0.168,  0.211, 0.251 ] \n",
        " \n",
        "#agarwal=> epsilon=[ 0.071, 0.1271, 0.2437, 0.27 ]\n",
        " \n",
        "\n",
        "    #gama=[0.0869, 0.0521,0.0782, 0.0608,0.0434, 0.1,0.069,0.0434,0.034]\n",
        "    epsilon=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
        "    beta_converge = [0.15]\n",
        "    #alpha = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
        "    alpha = [0]\n",
        "    zero_one = np.zeros(n, dtype = int) \n",
        "    \n",
        "    fi= np.zeros(n,dtype=int) \n",
        "#     for delta in delta1:\n",
        "    #4 gamma=[0.175442,    0.142103, 0.166039,    0.164754,  0.153465,    0.14,  0.104348   ]\n",
        "    #lp_equalized_odds_no_beta(data1,eps,y_test,e,beta_avg,alpha)\n",
        "    #1 gamma=[0.259147,   0.0730028, 0.210139, 0.0893443, 0.306931, 0.0933333,  0.0347826]\n",
        "    #gamma=[0.196178,0.126722,   0.179654, 0.140164,     0.153465,   0.133333,  0.0695652]\n",
        "\n",
        "  \n",
        "    gamma = [0.175442,    0.142103, 0.166039,    0.164754,  0.153465,    0.14,  0.104348 ]\n",
        "    for eps in epsilon:\n",
        "        for beta_avg in beta_converge:\n",
        "            print(\"----------------This is for covergence at beta = \",beta_avg, \" and beta_hat =\", eps, \"----------------\")\n",
        "            for a in alpha:\n",
        "                u1,u2=lp_equalized_odds(data,eps,y_test_pred,e,beta_avg,a)\n",
        "                #######################Disp_impact#######################  \n",
        "                print(\"gamma-epsilon-delta\",gamma,eps,delta)\n",
        "                accu_all=[]\n",
        "                DP_all=[]\n",
        "                precision_all=[]\n",
        "                recall_all=[]\n",
        "                acceptance_rate=np.zeros((7,28),dtype=float)\n",
        "                count=0\n",
        "                print(\"<--------------------------------------->\")\n",
        "            #        print(\"iteration t\",t)\n",
        "            #                 for alpha in np.arange(0,1.05,0.05):\n",
        "            #                     print(\"alpha: \",alpha)\n",
        "            #                     for i in range(n):\n",
        "\n",
        "            #                         z=random()\n",
        "            #                         if z < alpha:\n",
        "            #                                fi[i]= u1[i] \n",
        "\n",
        "            #                         else:\n",
        "            #                                fi[i]= r2[i]\n",
        "                \n",
        "                for i in range(n):\n",
        "                    fi[i] = u1[i]\n",
        "                    if (fi[i]==1):\n",
        "                        zero_one[i] = 1\n",
        "                    else:\n",
        "                        zero_one[i] = 0\n",
        "                ar=[]\n",
        "                #find_eo_stats(y_test,zero_one)\n",
        "                find_eo_stats_multiple(y_test,zero_one)\n",
        "\n",
        "\n",
        "                for j in range(s):\n",
        "                    print(\"sensitive attribute \",(j+1)) \n",
        "\n",
        "                    TP=0\n",
        "                    FP=0\n",
        "                    FN=0\n",
        "                    TN=0\n",
        "                    precision=0\n",
        "                    recall=0\n",
        "                    for i in range(n):\n",
        "                         if data[j][i]== 1 :                        \n",
        "                            if fi[i]==1 and r[i]==1:\n",
        "                                TP=TP+1\n",
        "                            if fi[i]==1 and r[i]==-1:\n",
        "                                FP=FP+1 \n",
        "                            if fi[i]==-1 and r[i]==1:\n",
        "                                FN=FN+1\n",
        "                            if fi[i]==-1 and r[i]==-1:\n",
        "                                TN=TN+1    \n",
        "                    if TP+FP !=0:\n",
        "                        precision=float(TP/(TP+FP))\n",
        "                    print(\"precision\",precision)\n",
        "                    if TP+FN !=0:    \n",
        "                        recall=float(TP/(TP+FN))\n",
        "                    print(\"recall\",recall)\n",
        "                    if FP+TN !=0:\n",
        "                        fpr = float(FP/(FP+TN))\n",
        "                    print(\"FPR\", fpr)    \n",
        "                    print(\"TP,FP,TN,FN\")\n",
        "                    print(TP,FP,TN,FN)\n",
        "                    a=0\n",
        "                    b=0\n",
        "                    acc1=0\n",
        "                    acc2=0\n",
        "                    for i in range(n):\n",
        "                            if data[j][i]== 1 :\n",
        "                                a=a+1\n",
        "                                if fi[i]==1:\n",
        "                                     acc1=acc1+1 \n",
        "\n",
        "            #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
        "                    a1=float(acc1/a)\n",
        "\n",
        "\n",
        "\n",
        "            #                         print(a)\n",
        "            #                         print(acc1)\n",
        "            #                         print(a1)\n",
        "                    ar.append(a1)\n",
        "\n",
        "                count = count+1\n",
        "                maxi=max(ar)\n",
        "                mini= min(ar)\n",
        "                DP=float(maxi-mini)\n",
        "                print(\"acceptance rates\")\n",
        "                print(ar)\n",
        "                print(\"DP\")\n",
        "                print(DP)\n",
        "                f_acc=0\n",
        "                for i in range(n):\n",
        "                     if fi[i] == r[i]:\n",
        "                            f_acc=f_acc+1\n",
        "                f_acc_l=float((f_acc*100)/n) \n",
        "\n",
        "#######################################################################33   \n",
        "\n",
        "#                         print(\"sensitive attribute \",(j+1)) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        TP=0\n",
        "        FP=0\n",
        "        FN=0\n",
        "        TN=0\n",
        "        precision=0\n",
        "        recall=0\n",
        "        for i in range(n):\n",
        "                if fi[i]==1 and r[i]==1:\n",
        "                    TP=TP+1\n",
        "                if fi[i]==1 and r[i]==-1:\n",
        "                    FP=FP+1 \n",
        "                if fi[i]==-1 and r[i]==1:\n",
        "                    FN=FN+1\n",
        "                if fi[i]==-1 and r[i]==-1:\n",
        "                    TN=TN+1    \n",
        "\n",
        "        if TP+FP!=0:\n",
        "            precision=float(TP/(TP+FP))\n",
        "        print(\"precision\",precision)\n",
        "        if TP+FN!=0:\n",
        "            recall=float(TP/(TP+FN))    \n",
        "\n",
        "        print(\"recall\",recall)\n",
        "        \n",
        "        accu = float((TP + TN)/n)\n",
        "        print(\"TP,FP,TN,FN\")\n",
        "        print(TP,FP,TN,FN)\n",
        "#       print(\"total ,fair accepted, aceeptance rate:\")             \n",
        "        a1=float(acc1/a)\n",
        "\n",
        "\n",
        "    print(\"<--------------------------------------->\")\n",
        "    alpha_weight=np.arange(0,1.05,.05)        \n",
        "    return accu_all,DP_all,acceptance_rate,alpha_weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EO\n",
        "accu_all,DP_all,acceptance_rate,alpha_weight = main2(sensitive, y_test, y_test_pred,e)"
      ],
      "metadata": {
        "id": "CJR0hc-m_BJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lNEgZXkv_BYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5Lvk9HEB_BbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TbTcXv6x_Bex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tuGkDrYQ_BiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Qz9sQUCn_BlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CvZtN1iZ_BsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6r5enNMfe33"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR9W01JZG5rs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}