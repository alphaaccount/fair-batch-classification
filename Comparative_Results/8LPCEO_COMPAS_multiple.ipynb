{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "8LPCEO_COMPAS_multiple.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1pIc6pd0QoG"
      },
      "source": [
        "# Import libraries necessary for this project\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "sns.set(style=\"darkgrid\")\n",
        "from time import time\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Import the three supervised learning models from sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA    \n",
        "\n",
        "# Pretty display for notebooks\n",
        "%matplotlib inline\n",
        "from random import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrV8Ba-Y0QpU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV8muil50QpV",
        "outputId": "b7e1a829-b620-4ab4-a0d3-c2456e9006e3"
      },
      "source": [
        "# without accuracy\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "# import pulp as p \n",
        "# from random import *\n",
        "data= pd.read_csv('data/propublica/compass.csv', skipinitialspace=True)\n",
        "# data = data1[data1[\"race\"].isin([\"african-american\", \"caucasian\"])]\n",
        "\n",
        "print(data['African_American'].value_counts())\n",
        "print(data['Female'].value_counts())\n",
        "# print(data.shape[0],data.shape[1])\n",
        "data=data.drop(columns=['id'])\n",
        "# print(data.head())\n",
        "# Age_Above_FourtyFive,Age_Below_TwentyFive, African_American,Female,  Two_yr_Recidivism  \n",
        "\n",
        "\n",
        "\n",
        "data_c = data.drop(columns=[ 'Two_yr_Recidivism' ])\n",
        "# print(sens)\n",
        "print(data_c.head())\n",
        "r=data[['Two_yr_Recidivism']]\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(data_c , r, test_size = 0.3, random_state=0, shuffle=True)\n",
        "\n",
        "X_test.reset_index(drop=True, inplace=True)\n",
        "# Y_test_pred.reset_index()\n",
        "\n",
        "Y_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(X_test)\n",
        "#print(Y_test_pred)\n",
        "print(Y_test)\n",
        "sens=X_test[['African_American','Female']]\n",
        "print(sens)\n",
        "p=sens.shape[0]\n",
        "\n",
        "\n",
        "sens1 = pd.get_dummies(sens, columns=['African_American','Female'], prefix =['african_american','female'])\n",
        "sensitive = sens1.T\n",
        "print(sensitive)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    3175\n",
            "0    2103\n",
            "Name: African_American, dtype: int64\n",
            "0    4247\n",
            "1    1031\n",
            "Name: Female, dtype: int64\n",
            "   Number_of_Priors  score_factor  ...  Female  Misdemeanor\n",
            "0                 0             0  ...       0            0\n",
            "1                 4             0  ...       0            0\n",
            "2                14             1  ...       0            0\n",
            "3                 0             0  ...       1            1\n",
            "4                 0             0  ...       0            0\n",
            "\n",
            "[5 rows x 7 columns]\n",
            "      Number_of_Priors  score_factor  ...  Female  Misdemeanor\n",
            "0                    0             1  ...       0            1\n",
            "1                    2             0  ...       0            1\n",
            "2                    5             0  ...       0            0\n",
            "3                    2             1  ...       0            0\n",
            "4                    1             0  ...       0            0\n",
            "...                ...           ...  ...     ...          ...\n",
            "1579                25             1  ...       0            1\n",
            "1580                 0             1  ...       1            0\n",
            "1581                20             1  ...       0            0\n",
            "1582                 2             1  ...       0            0\n",
            "1583                 3             1  ...       1            1\n",
            "\n",
            "[1584 rows x 7 columns]\n",
            "      Two_yr_Recidivism\n",
            "0                     1\n",
            "1                     0\n",
            "2                     1\n",
            "3                     1\n",
            "4                     1\n",
            "...                 ...\n",
            "1579                  1\n",
            "1580                  0\n",
            "1581                  0\n",
            "1582                  0\n",
            "1583                  0\n",
            "\n",
            "[1584 rows x 1 columns]\n",
            "      African_American  Female\n",
            "0                    1       0\n",
            "1                    1       0\n",
            "2                    0       0\n",
            "3                    1       0\n",
            "4                    1       0\n",
            "...                ...     ...\n",
            "1579                 1       0\n",
            "1580                 1       1\n",
            "1581                 1       0\n",
            "1582                 1       0\n",
            "1583                 1       1\n",
            "\n",
            "[1584 rows x 2 columns]\n",
            "                    0     1     2     3     4     ...  1579  1580  1581  1582  1583\n",
            "african_american_0     0     0     1     0     0  ...     0     0     0     0     0\n",
            "african_american_1     1     1     0     1     1  ...     1     1     1     1     1\n",
            "female_0               1     1     1     1     1  ...     1     0     1     1     0\n",
            "female_1               0     0     0     0     0  ...     0     1     0     0     1\n",
            "\n",
            "[4 rows x 1584 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myLFkLeO0Qpt"
      },
      "source": [
        "y_train = Y_train\n",
        "y_test = Y_test          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqHO5HE30QqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe88b8c-fade-4753-867e-67d2c1f11d5e"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score  \n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=251, max_depth=None, min_samples_split=50, random_state=0)\n",
        "\n",
        "#svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0,probability=True)\n",
        "rf.fit(X_train, y_train)\n",
        "print('The accuracy of the Random_Forest classifier on training data is {:.2f}'.format(rf.score(X_train, y_train)))\n",
        "print('The accuracy of the Random_Forest classifier on test data is {:.2f}'.format(rf.score(X_test, y_test)))\n",
        "print('####Train prediction Label###############################################')\n",
        "y_train_pred=rf.predict(X_train)\n",
        "#print(y_1)\n",
        "y_test_pred=rf.predict(X_test)\n",
        "e=rf.predict_proba(X_test)\n",
        "print(e)\n",
        "print(y_test_pred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the Random_Forest classifier on training data is 0.71\n",
            "The accuracy of the Random_Forest classifier on test data is 0.68\n",
            "####Train prediction Label###############################################\n",
            "[[0.43261605 0.56738395]\n",
            " [0.74575215 0.25424785]\n",
            " [0.59671785 0.40328215]\n",
            " ...\n",
            " [0.22524897 0.77475103]\n",
            " [0.42631319 0.57368681]\n",
            " [0.56690856 0.43309144]]\n",
            "[1 0 0 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-Z6M_1iJokJ",
        "outputId": "5b0c5ede-d6c9-43a5-ba8d-a566bdff19a7"
      },
      "source": [
        "sens=X_test[['African_American', 'Female']]\n",
        "sens_train_race= X_train[['African_American']]\n",
        "sens_train = X_train[['African_American', 'Female']]\n",
        "sens_train_sex = X_train[['Female']]\n",
        "\n",
        "sens_test_race = X_test[['African_American']]\n",
        "sens_test_sex = X_test[['Female']]\n",
        "\n",
        "print(sens)\n",
        "sens1=pd.get_dummies(sens, columns=['African_American','Female'], prefix =['African_American','Female'])\n",
        "sensitive=sens1.T\n",
        "print(sensitive) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      African_American  Female\n",
            "0                    1       0\n",
            "1                    1       0\n",
            "2                    0       0\n",
            "3                    1       0\n",
            "4                    1       0\n",
            "...                ...     ...\n",
            "1579                 1       0\n",
            "1580                 1       1\n",
            "1581                 1       0\n",
            "1582                 1       0\n",
            "1583                 1       1\n",
            "\n",
            "[1584 rows x 2 columns]\n",
            "                    0     1     2     3     4     ...  1579  1580  1581  1582  1583\n",
            "African_American_0     0     0     1     0     0  ...     0     0     0     0     0\n",
            "African_American_1     1     1     0     1     1  ...     1     1     1     1     1\n",
            "Female_0               1     1     1     1     1  ...     1     0     1     1     0\n",
            "Female_1               0     0     0     0     0  ...     0     1     0     0     1\n",
            "\n",
            "[4 rows x 1584 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvdtSA_HK5Wj",
        "outputId": "97c35248-6716-4bc0-f96a-ca856d520244"
      },
      "source": [
        "#----------------------------------FPR, TPR computation--------------------------------------------\n",
        "print(y_test.iloc[10])\n",
        "from random import *\n",
        "\n",
        "def find_eo_stats_multiple(y,y_pred):\n",
        "    m = 4\n",
        "    sens_stats = np.zeros((4,m), dtype = int)\n",
        "    sens_acc = np.zeros(m, dtype = float)\n",
        "    sizes = np.zeros(m, dtype = int)\n",
        "    #first row positives, second row negatives, third row true positive, fourth row false positive\n",
        "    \n",
        "    \n",
        "    for i in range(m):\n",
        "        for j in range(len(y)):\n",
        "            if(sensitive.iloc[i,j] == 1):\n",
        "                sizes[i] = sizes[i]+1\n",
        "                if(y_pred[j]==1):\n",
        "                    sens_acc[i] = sens_acc[i] + 1\n",
        "                if(y.iloc[j,0]==1):\n",
        "                    sens_stats[0][i] =sens_stats[0][i] + 1\n",
        "                if(y.iloc[j,0]==1 and y_pred[j]==1):\n",
        "                    sens_stats[2][i] =sens_stats[2][i] + 1\n",
        "                if(y.iloc[j,0]==0):\n",
        "                    sens_stats[1][i] =sens_stats[1][i] + 1\n",
        "                if(y.iloc[j,0]==0 and y_pred[j]==1):\n",
        "                    sens_stats[3][i] =sens_stats[3][i] + 1    \n",
        "        sens_acc[i] = sens_acc[i]/sizes[i]\n",
        "        #print(sens_acc[i],sizes[i])\n",
        "        \n",
        "    \n",
        "    TPR = np.zeros(m,dtype=float)\n",
        "    FPR = np.zeros(m,dtype=float)\n",
        "    \n",
        "    accu = 0\n",
        "    n = len(y)\n",
        "    for i in range(n):\n",
        "        if(y.iloc[i,0] == y_pred[i]):\n",
        "            accu = accu+1\n",
        "    \n",
        "    accu = accu/n\n",
        "    \n",
        "    max_tpr = -1 \n",
        "    min_tpr = 2\n",
        "    max_fpr = -1\n",
        "    min_fpr = 2\n",
        "    \n",
        "    for i in range(m):\n",
        "        TPR[i] = sens_stats[2][i]/sens_stats[0][i]\n",
        "        FPR[i] = sens_stats[3][i]/sens_stats[1][i]\n",
        "        if(TPR[i] >= max_tpr):\n",
        "            max_tpr = TPR[i]\n",
        "        if(TPR[i] <= min_tpr):\n",
        "            min_tpr = TPR[i]\n",
        "        if(FPR[i] >= max_fpr):\n",
        "            max_fpr = FPR[i]\n",
        "        if(FPR[i] <= min_fpr):\n",
        "            min_fpr = FPR[i]\n",
        "    \n",
        "    for i in  range(m):\n",
        "        print(\"TPR of the \",i,\"th sensitive groups is\",TPR[i])\n",
        "        \n",
        "    print(\"=====================\")    \n",
        "    for i in  range(m):\n",
        "        print(\"FPR of the \",i,\"th sensitive groups is\",FPR[i])\n",
        "    \n",
        "    print(\"=====================\")\n",
        "    for i in  range(m):    \n",
        "        print(\"Acceptance Rate of the \",i,\"th sensitive groups is\",sens_acc[i])\n",
        "    \n",
        "    DEO = abs(max_tpr-min_tpr) + abs(max_fpr-min_fpr)\n",
        "    \n",
        "    print(\"The Difference of Equalized odds of the classifier is=\",DEO)\n",
        "    print(\"Accuracy of the classifier\",accu)\n",
        "    \n",
        "#find_eo_stats_multiple(y_test,y_pred_CEO)\n",
        "#find_eo_stats_multiple(y_test,y_test_pred)\n",
        "\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Two_yr_Recidivism    0\n",
            "Name: 10, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Jd7mw3n3W_l",
        "outputId": "5df59545-8733-4a4f-984d-6c7306a834bc"
      },
      "source": [
        "pip install pulp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pulp\n",
            "  Downloading PuLP-2.6.0-py3-none-any.whl (14.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.2 MB 4.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: pulp\n",
            "Successfully installed pulp-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvtGr8My0Qqx"
      },
      "source": [
        "# bilal - am_ind asian black other white female male(actual precision sequence)\n",
        "# 6         5          4          2                1              0                  3\n",
        "\n",
        "# ours -s_male, s_female  r_white, r_black, r_asian-pac-islander','r_amer-indian-eskimo','r_other\n",
        "           \n",
        "# beta=[6         5          4          2                1              0                  3]\n",
        "\n",
        "# beta=[beta[6], beta[5],beta[4],beta[2],beta[1],beta[0],beta[3]]\n",
        "\n",
        "\n",
        "#bilal -female male  am_ind asian  black other white (actual acceptance rate sequence)\n",
        "#          0      1     2       3     4      5    6   \n",
        "# ours -s_male, s_female  r_white, r_black, r_asian-pac-islander','r_amer-indian-eskimo', 'r_other\n",
        "           \n",
        "# beta=[1       0        6          4            3                   2                    5]\n",
        "\n",
        "\n",
        "#NG\n",
        "import time\n",
        "#import gurobipy as gp\n",
        "#from gurobipy import GRB\n",
        "import pulp as p \n",
        "def lp_equalized_odds(data1,eps,y_test_pred,e,beta_avg,alpha):\n",
        "    import pulp as p \n",
        "    import math\n",
        "    \n",
        "    \n",
        "    m=data1.shape[0]\n",
        "    n=data1.shape[1]\n",
        "    print('dimension of data')\n",
        "    print(m,n)\n",
        "    \n",
        "        \n",
        "    ############### #  SORTED for ACCURACY ONLY ####\n",
        "    m=4\n",
        "    h1=[]\n",
        "    key1=[]\n",
        "    cost=np.zeros(n,dtype=int)\n",
        "    data2=np.zeros((m,n),dtype=int)\n",
        "    \n",
        "    for i in range(n):\n",
        "            h1.append(e[i][1])\n",
        "            key1.append(i)\n",
        "\n",
        "        \n",
        "#print(hc)\n",
        "#     print(key1)\n",
        "    \n",
        "    for i in range(1,len(h1)):\n",
        "        for j in range(i,0,-1):\n",
        "            var=0\n",
        "            var2=0\n",
        "            if h1[j-1]<h1[j]:\n",
        "                index=j\n",
        "                var=h1[j]\n",
        "                h1[j]=h1[j-1]\n",
        "                h1[j-1]=var\n",
        "\n",
        "                var2=key1[j]\n",
        "                key1[j]=key1[j-1]\n",
        "                key1[j-1]=var2\n",
        "            else:\n",
        "                break\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    for j in range(len(key1)):    \n",
        "         data2[0][key1[j]]=j+1\n",
        "    \n",
        "    for j in range(n):\n",
        "        summ=0\n",
        "        summ=summ+data2[0][j] \n",
        "        cost[j]=summ\n",
        "\n",
        "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
        "    solver = p.getSolver('PULP_CBC_CMD', timeLimit=20)\n",
        "   \n",
        "    \n",
        "#     X=np.zeros(n+1,dtype=p.LpVariable)\n",
        "    X=np.zeros(n+m+1,dtype=p.LpVariable)\n",
        "    Y=np.zeros(m,dtype=p.LpVariable)\n",
        "    \n",
        "    sizes=np.zeros(m,dtype=int)\n",
        "#     report_index(index,data1,e):  \n",
        "    max_size=0\n",
        "    for i in range(m):\n",
        "        count=0\n",
        "        for j in range(n):\n",
        "            if data1[i][j]==1:\n",
        "                count=count+1 \n",
        "        if count>max_size:\n",
        "            max_size=count\n",
        "        sizes[i]=count\n",
        "    print(sizes)    \n",
        "    ############################\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    ###############################\n",
        "    beta_actual = [0.2708333333333333, 0.5604166666666667, 0.4634920634920635, 0.37962962962962965]\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    select_sizes=np.zeros(m,dtype=int)\n",
        "   \n",
        "    size_final=np.zeros(m,dtype=int)\n",
        "\n",
        "    for i in range(m):\n",
        "        var1 = str(n+100+i)\n",
        "        Y[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Continuous')\n",
        "    \n",
        "    for i in range(n):\n",
        "        var1=str(i)       \n",
        "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
        "   \n",
        "    X[n]=p.LpVariable(str(n),lowBound=0,upBound=1,cat='Continuous')  \n",
        "\n",
        "    tpr = p.LpVariable(str(n+200),lowBound=0,upBound=1,cat='Continuous')  \n",
        "    fpr = p.LpVariable(str(n+201),lowBound=0,upBound=1,cat='Continuous')  \n",
        "\n",
        "#     for i in range(m):\n",
        "#         k=n+i+1\n",
        "#         var1=str(k)     \n",
        "#         alpha=(((sizes[i])*(sizes[i]+1))/2)\n",
        "#         X[i]=p.LpVariable(var1,lowBound=(((beta*sizes[i])*(beta*sizes[i]+1))/2),upBound=alpha,cat='Continuous')\n",
        "    \n",
        "        \n",
        "#     X[n]=  p.LpVariable(\"z1\",lowBound=0)\n",
        "    #X[n+1]=  p.LpVariable(\"z2\",lowBound=0)\n",
        "  \n",
        "\n",
        "    #########objective function#####################\n",
        "    \n",
        "#     Lp_prob += 2*X[n+1]+10*X[n+2]+9*X[n+3]+3*X[n+4]\n",
        "    #alpha=0.8\n",
        "    #beta_avg = 0.10\n",
        "    Lp_prob+= p.lpSum([(X[j])*cost[j] for j in range(n)]) \n",
        "    #Lp_prob+=1  \n",
        "    \n",
        "    #Lp_prob += Y[0]*sizes[0] + Y[1]*sizes[1] >= p.lpSum([Y[j]*sizes[j] for j in np.arange(2,6)])\n",
        "    #Lp_prob += Y[0]*sizes[0] + Y[1]*sizes[1] <= p.lpSum([Y[j]*sizes[j] for j in np.arange(2,6)])\n",
        "    \n",
        "    ##############constraint#################\n",
        "    #first select the  the number of make female in test data\n",
        "    #then apply the equalized odd constraints assuming \n",
        "    #look at all males which have been predicted positve/and all the females predicted negative\n",
        "    F_test = 0\n",
        "    M_test = 0\n",
        "        \n",
        "    #for i in range(len(y_test)):\n",
        "    #    if(data1[0][i]==1 and y_test.iloc[i]==1):\n",
        "    #        M_test= M_test+1\n",
        "    #    elif(data1[1][i]==1 and y_test.iloc[i]==1):\n",
        "    #        F_test= F_test+1\n",
        "    test_count = np.zeros(m, dtype = int)\n",
        "\n",
        "    for i in range(len(y_test)):\n",
        "      for j in range(m): \n",
        "        if(data1[j][i]==1 and y_test_pred[i]==1):\n",
        "            test_count[j] = test_count[j] +1\n",
        "                \n",
        "    \n",
        "    #Lp_prob += (p.lpSum([(X[j])*(data1[0][j])*y_test_pred[j] for j in range(n) if y_test_pred[j]==1])/M_test) <= (p.lpSum([(X[j])*(data1[1][j])*y_test_pred[j] for j in range(n) if y_test_pred[j]==1])/F_test) + 0.0009\n",
        "    #Lp_prob += (p.lpSum([(X[j])*(data1[0][j])*(1-y_test_pred[j]) for j in range(n) if y_test_pred[j]==0])/(sizes[0]-M_test)) <= (p.lpSum([(X[j])*(data1[1][j])*(1-y_test_pred[j]) for j in range(n) if y_test_pred[j]==0])/(sizes[1]-F_test))+ 0.0009\n",
        "    for i in range(m):   #TPR constraints\n",
        "      Lp_prob += (1/test_count[i])*p.lpSum([(X[j])*(data1[i][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1) ]) >= tpr \n",
        "      Lp_prob += (1/test_count[i])*p.lpSum([(X[j])*(data1[i][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1 )]) <= tpr + 0.1\n",
        "    for i in range(m):    #FPR constraints\n",
        "      Lp_prob += (1/(sizes[i]-test_count[i]))*p.lpSum([(X[j])*(data1[i][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0)]) >= fpr\n",
        "      Lp_prob += (1/(sizes[i]-test_count[i]))*p.lpSum([(X[j])*(data1[i][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0)]) <= fpr + 0.1\n",
        "\n",
        "    #Lp_prob += F_test*p.lpSum([(X[j])*(data1[0][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1) ]) <= M_test*p.lpSum([(X[j])*(data1[1][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1 )]) + 0.004\n",
        "    #Lp_prob += (sizes[1]-F_test)*p.lpSum([(X[j])*(data1[0][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0)]) <= (sizes[0]-M_test)*p.lpSum([(X[j])*(data1[1][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0 )]) + 0.004\n",
        "    \n",
        "\n",
        "\n",
        "    #Lp_prob += F_test*p.lpSum([(X[j])*(data1[0][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1 and y_test.iloc[j]==1) ]) <= M_test*p.lpSum([(X[j])*(data1[1][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1 and y_test.iloc[j]==1)]) + 0.01\n",
        "    #Lp_prob += (sizes[1]-F_test)*p.lpSum([(X[j])*(data1[0][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0 and y_test.iloc[j]==0)]) <= (sizes[0]-M_test)*p.lpSum([(X[j])*(data1[1][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0 and y_test.iloc[j]==0)]) + 0.01\n",
        "    \n",
        "    #Lp_prob += p.lpSum([(X[j])*(data1[0][j])*y_test.iloc[j] for j in range(n) if y_test.iloc[j]==1])/M_test <= p.lpSum([(X[j])*(data1[1][j])*y_test.iloc[j] for j in range(n) if y_test.iloc[j]==1])/F_test + 0.004\n",
        "    #Lp_prob += (sizes[1]-F_test)*p.lpSum([(X[j])*(data1[0][j])*(1-y_test.iloc[j]) for j in range(n) if y_test.iloc[j]==0])/M_test <= (sizes[0]-M_test)*p.lpSum([(X[j])*(data1[1][j])*(1-y_test.iloc[j]) for j in range(n) if y_test.iloc[j]==0])/F_test + 0.004\n",
        "    \n",
        "    for i in range(m):\n",
        "      #  if i<m:\n",
        "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) >= Y[i]*sizes[i]\n",
        "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) <= (Y[i]+0.1)*sizes[i]\n",
        "    \n",
        "    for i in range(m):\n",
        "        if beta_actual[i] >= beta_avg:\n",
        "            Lp_prob += Y[i] >= (1-alpha)*beta_actual[i] + alpha*beta_avg\n",
        "            Lp_prob += Y[i] <= beta_actual[i]\n",
        "        else:\n",
        "            Lp_prob += Y[i] >= (1-alpha)*beta_actual[i] + alpha*beta_avg\n",
        "            Lp_prob += Y[i] <= beta_avg \n",
        "    \n",
        "           \n",
        "    #Lp_prob+= p.lpSum([(X[j])*cost[j] for j in range(n)])>=100\n",
        "        \n",
        "    #####################################\n",
        "    #solver = p.CPLEX_PY()\n",
        "    #solver.buildSolverModel(Lp_prob)\n",
        "    #Lp_prob.solverModel.parameters.timelimit.set(60)\n",
        "    #solver.callSolver(P)\n",
        "    #status = solver.findSolutionValues(Lp_prob)\n",
        "    #################################################################\n",
        "    status = Lp_prob.solve(solver)   # Solver \n",
        "    print(p.LpStatus[status]) \n",
        "    print(\"objective is:\")        \n",
        "    print(p.value(Lp_prob.objective))\n",
        "    print(\"discripency is:\") \n",
        "    print(p.value(X[n]))\n",
        "    x=np.zeros(n,dtype=float)\n",
        "\n",
        "   # The solution status \n",
        "    Synth1={}\n",
        "    Synth2={}\n",
        "    # # Printing the final solution \n",
        "    for i in range(n):\n",
        "        if(p.value(X[i])==1):\n",
        "            Synth1[i]=1 \n",
        "            Synth2[i]=-1\n",
        "#             if(data1[2][i]==1):\n",
        "#                 print(\"no\")\n",
        "        else:\n",
        "            Synth1[i]=-1\n",
        "            Synth2[i]=1\n",
        "    Synthu1=Synth1  \n",
        "    Synthu2=Synth2  \n",
        "    \n",
        "              \n",
        "    return Synthu1,Synthu2   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHY2js_plw24",
        "outputId": "70a996db-b850-46a7-f191-2c32a3499483"
      },
      "source": [
        "pip install pulp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pulp\n",
            "  Downloading PuLP-2.5.1-py3-none-any.whl (41.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 41.2 MB 77 kB/s \n",
            "\u001b[?25hInstalling collected packages: pulp\n",
            "Successfully installed pulp-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zshSmo5w0QrH"
      },
      "source": [
        "#without accuracy ---> 2\n",
        "def main2(datax, y_test, y_test_pred,e): \n",
        "        \n",
        "    n=datax.shape[1]\n",
        "    s=datax.shape[0]    \n",
        "    data = np.zeros((s, n), dtype = int)\n",
        "    \n",
        "    r = np.zeros(n, dtype = int) \n",
        "    \n",
        "    for i in range(n):\n",
        "        if int(y_test.iloc[i])==1 :\n",
        "            r[i]=1\n",
        "        else :\n",
        "            r[i]= -1  \n",
        "    \n",
        "    r2 = np.zeros(n, dtype = int) \n",
        "    for i in range(n):\n",
        "        if int(y_test_pred[i])==1 :\n",
        "            r2[i]=1\n",
        "        else :\n",
        "            r2[i]= -1          \n",
        "    ar=[]\n",
        "    \n",
        "    for j in range(s):\n",
        "        print(\"sensitive attribute \",(j+1)) \n",
        "        a=0\n",
        "        b=0\n",
        "        acc1=0\n",
        "        acc2=0\n",
        "        for i in range(n):\n",
        "                data[j][i]= datax.iloc[j,i]\n",
        "                if data[j][i]== 1 :\n",
        "                    a=a+1\n",
        "                    if r[i]==1:\n",
        "                         acc1=acc1+1 \n",
        "\n",
        "        print(\"ACTUAL----------total ,accepted, aceeptance rate:\")             \n",
        "        a1=float(acc1/a)\n",
        "        print(a)\n",
        "        \n",
        "        print(acc1)\n",
        "        print(a1)\n",
        "        ar.append(a1)\n",
        "        \n",
        "    maxi= max(ar)\n",
        "    mini= min(ar)\n",
        "    DP=float(maxi-mini)\n",
        "    print(\"data acceptance rates\")\n",
        "    print(ar)\n",
        "    print(\"data DP\")\n",
        "    print(DP)\n",
        "    \n",
        "    ar=[]\n",
        "    \n",
        "    for j in range(s):\n",
        "        print(\"sensitive attribute \",(j+1)) \n",
        "        a=0\n",
        "        b=0\n",
        "        acc1=0\n",
        "        acc2=0\n",
        "        prec=0\n",
        "        reca=0\n",
        "        accur=0\n",
        "        FP=0\n",
        "        FN=0\n",
        "        TP=0\n",
        "        TN=0\n",
        "        for i in range(n):\n",
        "             if data[j][i]== 1 :\n",
        "                    a=a+1\n",
        "                    if r2[i]==1:\n",
        "                        acc1=acc1+1 \n",
        "                        if r[i]==1:\n",
        "                            TP=TP+1\n",
        "                        else:\n",
        "                             FP=FP+1                \n",
        "                    else:\n",
        "                        if r[i]==1:\n",
        "                            FN=FN+1\n",
        "                        else:\n",
        "                            TN=TN+1    \n",
        "        \n",
        "        print(\"prec reca accuracy for each sens\") \n",
        "        prec= float(TP/(TP+FP))\n",
        "        reca= float(TP/(TP+FN))\n",
        "        accur= float((TP+TN)/a)\n",
        "        print(prec,reca,accur)\n",
        "        \n",
        "        print(\"RanomForest----------total , accepted, aceeptance rate:\")             \n",
        "        \n",
        "        a1=float(acc1/a)\n",
        "        print(a)\n",
        "        \n",
        "        print(acc1)\n",
        "        print(a1)\n",
        "        ar.append(a1)\n",
        "        \n",
        "    maxi= max(ar)\n",
        "    mini= min(ar)\n",
        "    DP=float(maxi-mini)\n",
        "    print(\"data acceptance rates\")\n",
        "    print(ar)\n",
        "    print(\"data DP\")\n",
        "    print(DP) \n",
        "    \n",
        "    print(\"SVM accuracy--------------------------\")\n",
        "    prec=0\n",
        "    reca=0\n",
        "    accur=0\n",
        "    FP=0\n",
        "    FN=0\n",
        "    TP=0\n",
        "    TN=0\n",
        "    for i in range(n):\n",
        "            if r2[i]==1:\n",
        "                acc1=acc1+1 \n",
        "                if r[i]==1:\n",
        "                    TP=TP+1\n",
        "                else:\n",
        "                     FP=FP+1                \n",
        "            else:\n",
        "                if r[i]==1:\n",
        "                     FN=FN+1\n",
        "                else:\n",
        "                     TN=TN+1    \n",
        "\n",
        "        \n",
        "    prec= float(TP/(TP+FP))\n",
        "    reca= float(TP/(TP+FN))\n",
        "    accur= float((TP+TN)/n)\n",
        "    print(prec,reca,accur)\n",
        "    \n",
        "    \n",
        "#     delta1=[.70,.75,.80,.85,.90,.95]\n",
        "    #gamma=.05,.06,.07\n",
        "    #delta1=[.80,.85,.90,.95]\n",
        "# (for reproducibility)  \n",
        "\n",
        "# delta1=[.8], gama=[.1], epsilon=[.05]  \n",
        "# delta1=[.8], gama=[.15], epsilon=[.01]\n",
        " \n",
        "#     delta1=np.arange(1,.79,-.01)\n",
        "    delta=1\n",
        "#     gama=[.05,.1,.15,.2,.25]\n",
        "#     epsilon=[.01,.02,.05,.1,.15,.20,.25,.30,.35,.40,.50]\n",
        "\n",
        "#ADULT ZAFAR =? epsilon=[0.088 ,0.1656, 0.168,  0.211, 0.251 ] \n",
        " \n",
        "#agarwal=> epsilon=[ 0.071, 0.1271, 0.2437, 0.27 ]\n",
        " \n",
        "\n",
        "    #gama=[0.0869, 0.0521,0.0782, 0.0608,0.0434, 0.1,0.069,0.0434,0.034]\n",
        "    epsilon=[.1]\n",
        "    beta_converge = [0.15,0.20]\n",
        "    alpha = [0]\n",
        "    \n",
        "    zero_one = np.zeros(n, dtype = int) \n",
        "    \n",
        "    fi= np.zeros(n,dtype=int) \n",
        "#     for delta in delta1:\n",
        "    #4 gamma=[0.175442,    0.142103, 0.166039,    0.164754,  0.153465,    0.14,  0.104348   ]\n",
        "    #lp_equalized_odds_no_beta(data1,eps,y_test,e,beta_avg,alpha)\n",
        "    #1 gamma=[0.259147,   0.0730028, 0.210139, 0.0893443, 0.306931, 0.0933333,  0.0347826]\n",
        "    #gamma=[0.196178,0.126722,   0.179654, 0.140164,     0.153465,   0.133333,  0.0695652]\n",
        "\n",
        "  \n",
        "    gamma = [0.175442,    0.142103, 0.166039,    0.164754,  0.153465,    0.14,  0.104348 ]\n",
        "    for eps in epsilon:\n",
        "        for beta_avg in beta_converge:\n",
        "            print(\"----------------This is for covergence at beta = \",beta_avg, \" ----------------\")\n",
        "            for a in alpha:\n",
        "                u1,u2=lp_equalized_odds(data,eps,y_test_pred,e,beta_avg,a)\n",
        "                #######################Disp_impact#######################  \n",
        "                print(\"gamma-epsilon-delta\",gamma,eps,delta)\n",
        "                accu_all=[]\n",
        "                DP_all=[]\n",
        "                precision_all=[]\n",
        "                recall_all=[]\n",
        "                acceptance_rate=np.zeros((7,28),dtype=float)\n",
        "                count=0\n",
        "                print(\"<--------------------------------------->\")\n",
        "            #        print(\"iteration t\",t)\n",
        "            #                 for alpha in np.arange(0,1.05,0.05):\n",
        "            #                     print(\"alpha: \",alpha)\n",
        "            #                     for i in range(n):\n",
        "\n",
        "            #                         z=random()\n",
        "            #                         if z < alpha:\n",
        "            #                                fi[i]= u1[i] \n",
        "\n",
        "            #                         else:\n",
        "            #                                fi[i]= r2[i]\n",
        "                \n",
        "                for i in range(n):\n",
        "                    fi[i] = u1[i]\n",
        "                    if (fi[i]==1):\n",
        "                        zero_one[i] = 1\n",
        "                    else:\n",
        "                        zero_one[i] = 0\n",
        "                ar=[]\n",
        "                #find_eo_stats(y_test,zero_one)\n",
        "                find_eo_stats_multiple(y_test,zero_one)\n",
        "\n",
        "\n",
        "                for j in range(s):\n",
        "                    print(\"sensitive attribute \",(j+1)) \n",
        "\n",
        "                    TP=0\n",
        "                    FP=0\n",
        "                    FN=0\n",
        "                    TN=0\n",
        "                    precision=0\n",
        "                    recall=0\n",
        "                    for i in range(n):\n",
        "                         if data[j][i]== 1 :                        \n",
        "                            if fi[i]==1 and r[i]==1:\n",
        "                                TP=TP+1\n",
        "                            if fi[i]==1 and r[i]==-1:\n",
        "                                FP=FP+1 \n",
        "                            if fi[i]==-1 and r[i]==1:\n",
        "                                FN=FN+1\n",
        "                            if fi[i]==-1 and r[i]==-1:\n",
        "                                TN=TN+1    \n",
        "                    if TP+FP !=0:\n",
        "                        precision=float(TP/(TP+FP))\n",
        "                    print(\"precision\",precision)\n",
        "                    if TP+FN !=0:    \n",
        "                        recall=float(TP/(TP+FN))\n",
        "                    print(\"recall\",recall)\n",
        "                    if FP+TN !=0:\n",
        "                        fpr = float(FP/(FP+TN))\n",
        "                    print(\"FPR\", fpr)    \n",
        "                    print(\"TP,FP,TN,FN\")\n",
        "                    print(TP,FP,TN,FN)\n",
        "                    a=0\n",
        "                    b=0\n",
        "                    acc1=0\n",
        "                    acc2=0\n",
        "                    for i in range(n):\n",
        "                            if data[j][i]== 1 :\n",
        "                                a=a+1\n",
        "                                if fi[i]==1:\n",
        "                                     acc1=acc1+1 \n",
        "\n",
        "            #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
        "                    a1=float(acc1/a)\n",
        "\n",
        "\n",
        "\n",
        "            #                         print(a)\n",
        "            #                         print(acc1)\n",
        "            #                         print(a1)\n",
        "                    ar.append(a1)\n",
        "\n",
        "                count = count+1\n",
        "                maxi=max(ar)\n",
        "                mini= min(ar)\n",
        "                DP=float(maxi-mini)\n",
        "                print(\"acceptance rates\")\n",
        "                print(ar)\n",
        "                print(\"DP\")\n",
        "                print(DP)\n",
        "                f_acc=0\n",
        "                for i in range(n):\n",
        "                     if fi[i] == r[i]:\n",
        "                            f_acc=f_acc+1\n",
        "                f_acc_l=float((f_acc*100)/n) \n",
        "\n",
        "#######################################################################33   \n",
        "\n",
        "#                         print(\"sensitive attribute \",(j+1)) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        TP=0\n",
        "        FP=0\n",
        "        FN=0\n",
        "        TN=0\n",
        "        precision=0\n",
        "        recall=0\n",
        "        for i in range(n):\n",
        "                if fi[i]==1 and r[i]==1:\n",
        "                    TP=TP+1\n",
        "                if fi[i]==1 and r[i]==-1:\n",
        "                    FP=FP+1 \n",
        "                if fi[i]==-1 and r[i]==1:\n",
        "                    FN=FN+1\n",
        "                if fi[i]==-1 and r[i]==-1:\n",
        "                    TN=TN+1    \n",
        "\n",
        "        if TP+FP!=0:\n",
        "            precision=float(TP/(TP+FP))\n",
        "        print(\"precision\",precision)\n",
        "        if TP+FN!=0:\n",
        "            recall=float(TP/(TP+FN))    \n",
        "\n",
        "        print(\"recall\",recall)\n",
        "        \n",
        "        accu = float((TP + TN)/n)\n",
        "        print(\"TP,FP,TN,FN\")\n",
        "        print(TP,FP,TN,FN)\n",
        "#       print(\"total ,fair accepted, aceeptance rate:\")             \n",
        "        a1=float(acc1/a)\n",
        "\n",
        "\n",
        "    print(\"<--------------------------------------->\")\n",
        "    alpha_weight=np.arange(0,1.05,.05)        \n",
        "    return accu_all,DP_all,acceptance_rate,alpha_weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5OjohSJ0QrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66476a2-0411-4d80-9e3e-f7c7a070bd4c"
      },
      "source": [
        "accu_all,DP_all,acceptance_rate,alpha_weight = main2(sensitive, y_test, y_test_pred,e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sensitive attribute  1\n",
            "ACTUAL----------total ,accepted, aceeptance rate:\n",
            "624\n",
            "238\n",
            "0.3814102564102564\n",
            "sensitive attribute  2\n",
            "ACTUAL----------total ,accepted, aceeptance rate:\n",
            "960\n",
            "484\n",
            "0.5041666666666667\n",
            "sensitive attribute  3\n",
            "ACTUAL----------total ,accepted, aceeptance rate:\n",
            "1260\n",
            "599\n",
            "0.4753968253968254\n",
            "sensitive attribute  4\n",
            "ACTUAL----------total ,accepted, aceeptance rate:\n",
            "324\n",
            "123\n",
            "0.37962962962962965\n",
            "data acceptance rates\n",
            "[0.3814102564102564, 0.5041666666666667, 0.4753968253968254, 0.37962962962962965]\n",
            "data DP\n",
            "0.124537037037037\n",
            "sensitive attribute  1\n",
            "prec reca accuracy for each sens\n",
            "0.6341463414634146 0.4369747899159664 0.6891025641025641\n",
            "RanomForest----------total , accepted, aceeptance rate:\n",
            "624\n",
            "164\n",
            "0.26282051282051283\n",
            "sensitive attribute  2\n",
            "prec reca accuracy for each sens\n",
            "0.6469534050179212 0.7458677685950413 0.6666666666666666\n",
            "RanomForest----------total , accepted, aceeptance rate:\n",
            "960\n",
            "558\n",
            "0.58125\n",
            "sensitive attribute  3\n",
            "prec reca accuracy for each sens\n",
            "0.6355283307810107 0.6928213689482471 0.665079365079365\n",
            "RanomForest----------total , accepted, aceeptance rate:\n",
            "1260\n",
            "653\n",
            "0.5182539682539683\n",
            "sensitive attribute  4\n",
            "prec reca accuracy for each sens\n",
            "0.7246376811594203 0.4065040650406504 0.7160493827160493\n",
            "RanomForest----------total , accepted, aceeptance rate:\n",
            "324\n",
            "69\n",
            "0.21296296296296297\n",
            "data acceptance rates\n",
            "[0.26282051282051283, 0.58125, 0.5182539682539683, 0.21296296296296297]\n",
            "data DP\n",
            "0.3682870370370371\n",
            "SVM accuracy--------------------------\n",
            "0.6440443213296398 0.6440443213296398 0.6755050505050505\n",
            "----------------This is for covergence at beta =  0.15  ----------------\n",
            "dimension of data\n",
            "4 1584\n",
            "[ 624  960 1260  324]\n",
            "Optimal\n",
            "objective is:\n",
            "294522.0\n",
            "discripency is:\n",
            "None\n",
            "gamma-epsilon-delta [0.175442, 0.142103, 0.166039, 0.164754, 0.153465, 0.14, 0.104348] 0.1 1\n",
            "<--------------------------------------->\n",
            "TPR of the  0 th sensitive groups is 0.47478991596638653\n",
            "TPR of the  1 th sensitive groups is 0.7128099173553719\n",
            "TPR of the  2 th sensitive groups is 0.654424040066778\n",
            "TPR of the  3 th sensitive groups is 0.5365853658536586\n",
            "=====================\n",
            "FPR of the  0 th sensitive groups is 0.21502590673575128\n",
            "FPR of the  1 th sensitive groups is 0.4054621848739496\n",
            "FPR of the  2 th sensitive groups is 0.3313161875945537\n",
            "FPR of the  3 th sensitive groups is 0.2835820895522388\n",
            "=====================\n",
            "Acceptance Rate of the  0 th sensitive groups is 0.3141025641025641\n",
            "Acceptance Rate of the  1 th sensitive groups is 0.5604166666666667\n",
            "Acceptance Rate of the  2 th sensitive groups is 0.4849206349206349\n",
            "Acceptance Rate of the  3 th sensitive groups is 0.37962962962962965\n",
            "The Difference of Equalized odds of the classifier is= 0.4284562795271837\n",
            "Accuracy of the classifier 0.6590909090909091\n",
            "sensitive attribute  1\n",
            "precision 0.576530612244898\n",
            "recall 0.47478991596638653\n",
            "FPR 0.21502590673575128\n",
            "TP,FP,TN,FN\n",
            "113 83 303 125\n",
            "sensitive attribute  2\n",
            "precision 0.6412639405204461\n",
            "recall 0.7128099173553719\n",
            "FPR 0.4054621848739496\n",
            "TP,FP,TN,FN\n",
            "345 193 283 139\n",
            "sensitive attribute  3\n",
            "precision 0.6415711947626841\n",
            "recall 0.654424040066778\n",
            "FPR 0.3313161875945537\n",
            "TP,FP,TN,FN\n",
            "392 219 442 207\n",
            "sensitive attribute  4\n",
            "precision 0.5365853658536586\n",
            "recall 0.5365853658536586\n",
            "FPR 0.2835820895522388\n",
            "TP,FP,TN,FN\n",
            "66 57 144 57\n",
            "acceptance rates\n",
            "[0.3141025641025641, 0.5604166666666667, 0.4849206349206349, 0.37962962962962965]\n",
            "DP\n",
            "0.24631410256410258\n",
            "----------------This is for covergence at beta =  0.2  ----------------\n",
            "dimension of data\n",
            "4 1584\n",
            "[ 624  960 1260  324]\n",
            "Optimal\n",
            "objective is:\n",
            "294522.0\n",
            "discripency is:\n",
            "None\n",
            "gamma-epsilon-delta [0.175442, 0.142103, 0.166039, 0.164754, 0.153465, 0.14, 0.104348] 0.1 1\n",
            "<--------------------------------------->\n",
            "TPR of the  0 th sensitive groups is 0.47478991596638653\n",
            "TPR of the  1 th sensitive groups is 0.7128099173553719\n",
            "TPR of the  2 th sensitive groups is 0.654424040066778\n",
            "TPR of the  3 th sensitive groups is 0.5365853658536586\n",
            "=====================\n",
            "FPR of the  0 th sensitive groups is 0.21502590673575128\n",
            "FPR of the  1 th sensitive groups is 0.4054621848739496\n",
            "FPR of the  2 th sensitive groups is 0.3313161875945537\n",
            "FPR of the  3 th sensitive groups is 0.2835820895522388\n",
            "=====================\n",
            "Acceptance Rate of the  0 th sensitive groups is 0.3141025641025641\n",
            "Acceptance Rate of the  1 th sensitive groups is 0.5604166666666667\n",
            "Acceptance Rate of the  2 th sensitive groups is 0.4849206349206349\n",
            "Acceptance Rate of the  3 th sensitive groups is 0.37962962962962965\n",
            "The Difference of Equalized odds of the classifier is= 0.4284562795271837\n",
            "Accuracy of the classifier 0.6590909090909091\n",
            "sensitive attribute  1\n",
            "precision 0.576530612244898\n",
            "recall 0.47478991596638653\n",
            "FPR 0.21502590673575128\n",
            "TP,FP,TN,FN\n",
            "113 83 303 125\n",
            "sensitive attribute  2\n",
            "precision 0.6412639405204461\n",
            "recall 0.7128099173553719\n",
            "FPR 0.4054621848739496\n",
            "TP,FP,TN,FN\n",
            "345 193 283 139\n",
            "sensitive attribute  3\n",
            "precision 0.6415711947626841\n",
            "recall 0.654424040066778\n",
            "FPR 0.3313161875945537\n",
            "TP,FP,TN,FN\n",
            "392 219 442 207\n",
            "sensitive attribute  4\n",
            "precision 0.5365853658536586\n",
            "recall 0.5365853658536586\n",
            "FPR 0.2835820895522388\n",
            "TP,FP,TN,FN\n",
            "66 57 144 57\n",
            "acceptance rates\n",
            "[0.3141025641025641, 0.5604166666666667, 0.4849206349206349, 0.37962962962962965]\n",
            "DP\n",
            "0.24631410256410258\n",
            "precision 0.6239782016348774\n",
            "recall 0.6343490304709142\n",
            "TP,FP,TN,FN\n",
            "458 276 586 264\n",
            "<--------------------------------------->\n"
          ]
        }
      ]
    }
  ]
}