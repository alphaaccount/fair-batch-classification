{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8LPCEO_Bank_multiple.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BGYHvTH6i5J"
      },
      "source": [
        "# Import libraries necessary for this project\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "sns.set(style=\"darkgrid\")\n",
        "from time import time\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Import the three supervised learning models from sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA    \n",
        "\n",
        "# Pretty display for notebooks\n",
        "%matplotlib inline\n",
        "from random import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdjL3zL66i5_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBquvTQN6i6B",
        "outputId": "d2eb9911-b754-4a93-8ff2-b7e947ede13b"
      },
      "source": [
        "#FOR BILAL\n",
        "# without accuracy\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "# import pulp as p \n",
        "# from random import *\n",
        "data= pd.read_csv('data/bank_train.csv',skipinitialspace=True)\n",
        "\n",
        "print(data['marital'].value_counts())\n",
        "#marital\n",
        "#U=80, M=24928, S=11568, D=4612\n",
        "# m_3, m_0, m_1, m_2\n",
        "#age\n",
        "#>60 and <25= a_1\n",
        "#>=25and <=60 =a_2\n",
        "# print(data.head())\n",
        "# print(data.shape[0],data.shape[1])\n",
        "\n",
        "#sensitive columns name 0='age',2='marital'\n",
        "\n",
        "data_c = data.drop(columns=['age_group','y'])\n",
        "# print(sens)\n",
        "r=data[['y']]\n",
        "for i in range(data_c.shape[0]):\n",
        "    if data_c.loc[i,'age'] > 60 or data_c.loc[i,'age'] < 25 :\n",
        "              data_c.loc[i,'age'] = 0 \n",
        "    else :\n",
        "              data_c.loc[i,'age'] = 1 \n",
        "            \n",
        "X_train, X_test, Y_train, Y_test = train_test_split(data_c , r, test_size=0.3, random_state=1234567, shuffle = True)\n",
        "\n",
        "X_test.reset_index(drop=True, inplace=True)\n",
        "# Y_test_pred.reset_index()\n",
        "Y_test.reset_index(drop=True, inplace=True)\n",
        "print(X_test)\n",
        "#print(Y_test_pred)\n",
        "print(Y_test)\n",
        "sens=X_test[['age','marital']]\n",
        "print(sens)\n",
        "p=sens.shape[0]\n",
        "y_train = Y_train\n",
        "y_test = Y_test\n",
        "          \n",
        "for i in range(0,p):\n",
        "    if sens.loc[i,'age'] > 60 or sens.loc[i,'age'] < 25 :\n",
        "               sens.loc[i,'age'] = 1 \n",
        "    else :\n",
        "               sens.loc[i,'age'] = 2  \n",
        "            \n",
        "sens1 = pd.get_dummies(sens, columns=['age','marital'], prefix =['a','m'])\n",
        "print(sens1.head())\n",
        "sensitive = sens1.T\n",
        "\n",
        "print(sensitive)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    24928\n",
            "1    11568\n",
            "2     4612\n",
            "3       80\n",
            "Name: marital, dtype: int64\n",
            "       age  job  marital  ...  cons.conf.idx  euribor3m  nr.employed\n",
            "0        1   11        1  ...          -40.8      1.268       5076.2\n",
            "1        1    2        1  ...          -46.2      1.244       5099.1\n",
            "2        1    3        0  ...          -36.4      4.859       5191.0\n",
            "3        1    1        0  ...          -46.2      1.334       5099.1\n",
            "4        1    1        2  ...          -47.1      1.405       5099.1\n",
            "...    ...  ...      ...  ...            ...        ...          ...\n",
            "12352    1    2        0  ...          -36.4      4.856       5191.0\n",
            "12353    1    2        1  ...          -36.4      4.857       5191.0\n",
            "12354    0   11        1  ...          -40.8      1.262       5076.2\n",
            "12355    0    9        0  ...          -29.8      0.770       5017.5\n",
            "12356    1    3        0  ...          -36.4      4.858       5191.0\n",
            "\n",
            "[12357 rows x 20 columns]\n",
            "       y\n",
            "0      1\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "...   ..\n",
            "12352  0\n",
            "12353  0\n",
            "12354  1\n",
            "12355  0\n",
            "12356  0\n",
            "\n",
            "[12357 rows x 1 columns]\n",
            "       age  marital\n",
            "0        1        1\n",
            "1        1        1\n",
            "2        1        0\n",
            "3        1        0\n",
            "4        1        2\n",
            "...    ...      ...\n",
            "12352    1        0\n",
            "12353    1        1\n",
            "12354    0        1\n",
            "12355    0        0\n",
            "12356    1        0\n",
            "\n",
            "[12357 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   a_1  m_0  m_1  m_2  m_3\n",
            "0    1    0    1    0    0\n",
            "1    1    0    1    0    0\n",
            "2    1    1    0    0    0\n",
            "3    1    1    0    0    0\n",
            "4    1    0    0    1    0\n",
            "     0      1      2      3      4      ...  12352  12353  12354  12355  12356\n",
            "a_1      1      1      1      1      1  ...      1      1      1      1      1\n",
            "m_0      0      0      1      1      0  ...      1      0      0      1      1\n",
            "m_1      1      1      0      0      0  ...      0      1      1      0      0\n",
            "m_2      0      0      0      0      1  ...      0      0      0      0      0\n",
            "m_3      0      0      0      0      0  ...      0      0      0      0      0\n",
            "\n",
            "[5 rows x 12357 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U__SXXh6i6o",
        "outputId": "d821c2d7-8d1a-47ca-b264-c278aae22209"
      },
      "source": [
        "          \n",
        "for i in range(sens.shape[0]):\n",
        "    if X_test.iloc[i,0] == 1:\n",
        "               sens.iloc[i,0] = 1 \n",
        "    else :\n",
        "               sens.iloc[i,0] = 0  \n",
        "            \n",
        "sens1 = pd.get_dummies(sens, columns=['age','marital'], prefix =['a','m'])\n",
        "print(sens1.head())\n",
        "sensitive = sens1.T\n",
        "\n",
        "print(sensitive)\n",
        "\n",
        "\n",
        "\n",
        "count1 = 0\n",
        "count2 = 0\n",
        "for k in range(sens.shape[0]):\n",
        "    if sensitive.iloc[0,k] == 1 :\n",
        "               count1 = count1 + 1\n",
        "    else :\n",
        "               count2 = count2 + 1\n",
        "print(count1,count2)            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   a_0  a_1  m_0  m_1  m_2  m_3\n",
            "0    0    1    0    1    0    0\n",
            "1    0    1    0    1    0    0\n",
            "2    0    1    1    0    0    0\n",
            "3    0    1    1    0    0    0\n",
            "4    0    1    0    0    1    0\n",
            "     0      1      2      3      4      ...  12352  12353  12354  12355  12356\n",
            "a_0      0      0      0      0      0  ...      0      0      1      1      0\n",
            "a_1      1      1      1      1      1  ...      1      1      0      0      1\n",
            "m_0      0      0      1      1      0  ...      1      0      0      1      1\n",
            "m_1      1      1      0      0      0  ...      0      1      1      0      0\n",
            "m_2      0      0      0      0      1  ...      0      0      0      0      0\n",
            "m_3      0      0      0      0      0  ...      0      0      0      0      0\n",
            "\n",
            "[6 rows x 12357 columns]\n",
            "618 11739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n81jxxnG6i7A",
        "outputId": "fda21e10-a4a2-4d8e-a157-bd87beb6519c"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score  \n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0,probability=True)\n",
        "y_train = Y_train\n",
        "y_test = Y_test\n",
        "rf = RandomForestClassifier(n_estimators=150, max_depth=None, min_samples_split=30, random_state=0)\n",
        "rf.fit(X_train, y_train)\n",
        "print('The accuracy of the Logistic_Regression classifier on training data is {:.2f}'.format(rf.score(X_train, y_train)))\n",
        "print('The accuracy of the Logistic_Regression classifier on test data is {:.2f}'.format(rf.score(X_test, y_test)))\n",
        "print('####Train prediction Label###############################################')\n",
        "y_train_pred=rf.predict(X_train)\n",
        "#print(y_1)\n",
        "y_test_pred=rf.predict(X_test)\n",
        "e=rf.predict_proba(X_test)\n",
        "print(e)\n",
        "print(y_test_pred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the Logistic_Regression classifier on training data is 0.94\n",
            "The accuracy of the Logistic_Regression classifier on test data is 0.92\n",
            "####Train prediction Label###############################################\n",
            "[[0.38074946 0.61925054]\n",
            " [0.9791372  0.0208628 ]\n",
            " [0.99007255 0.00992745]\n",
            " ...\n",
            " [0.48568227 0.51431773]\n",
            " [0.42347019 0.57652981]\n",
            " [0.97919193 0.02080807]]\n",
            "[1 0 0 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXo2j0a2ZGas",
        "outputId": "658ca0a3-c96a-4a29-e3aa-9bb47eccdbf2"
      },
      "source": [
        "sens1=pd.get_dummies(sens, columns=['age','marital'], prefix =['age','marital'])\n",
        "\n",
        "sens=X_test[['age','marital']]\n",
        "sens_train_race= X_train[['age']]\n",
        "sens_train = X_train[['age','marital']]\n",
        "sens_train_sex = X_train[['marital']]\n",
        "\n",
        "sens_test_race = X_test[['age']]\n",
        "sens_test_sex = X_test[['marital']]\n",
        "\n",
        "print(sens)\n",
        "sensitive=sens1.T\n",
        "print(sensitive) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       age  marital\n",
            "0        1        1\n",
            "1        1        1\n",
            "2        1        0\n",
            "3        1        0\n",
            "4        1        2\n",
            "...    ...      ...\n",
            "12352    1        0\n",
            "12353    1        1\n",
            "12354    0        1\n",
            "12355    0        0\n",
            "12356    1        0\n",
            "\n",
            "[12357 rows x 2 columns]\n",
            "           0      1      2      3      4      ...  12352  12353  12354  12355  12356\n",
            "age_0          0      0      0      0      0  ...      0      0      1      1      0\n",
            "age_1          1      1      1      1      1  ...      1      1      0      0      1\n",
            "marital_0      0      0      1      1      0  ...      1      0      0      1      1\n",
            "marital_1      1      1      0      0      0  ...      0      1      1      0      0\n",
            "marital_2      0      0      0      0      1  ...      0      0      0      0      0\n",
            "marital_3      0      0      0      0      0  ...      0      0      0      0      0\n",
            "\n",
            "[6 rows x 12357 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM0yo7U46i7v"
      },
      "source": [
        "#----------------------------------FPR, TPR computation--------------------------------------------\n",
        "#print(y_test[10])\n",
        "from random import *\n",
        "\n",
        "def find_eo_stats_multiple(y,y_pred):\n",
        "    m = 6\n",
        "    sens_stats = np.zeros((4,m), dtype = int)\n",
        "    sens_acc = np.zeros(m, dtype = float)\n",
        "    sizes = np.zeros(m, dtype = int)\n",
        "    #first row positives, second row negatives, third row true positive, fourth row false positive\n",
        "    \n",
        "    \n",
        "    for i in range(m):\n",
        "        for j in range(len(y)):\n",
        "            if(sensitive.iloc[i,j] == 1):\n",
        "                sizes[i] = sizes[i]+1\n",
        "                if(y_pred[j]==1):\n",
        "                    sens_acc[i] = sens_acc[i] + 1\n",
        "                if(y.iloc[j,0]==1):\n",
        "                    sens_stats[0][i] =sens_stats[0][i] + 1\n",
        "                if(y.iloc[j,0]==1 and y_pred[j]==1):\n",
        "                    sens_stats[2][i] =sens_stats[2][i] + 1\n",
        "                if(y.iloc[j,0]==0):\n",
        "                    sens_stats[1][i] =sens_stats[1][i] + 1\n",
        "                if(y.iloc[j,0]==0 and y_pred[j]==1):\n",
        "                    sens_stats[3][i] =sens_stats[3][i] + 1    \n",
        "        sens_acc[i] = sens_acc[i]/sizes[i]\n",
        "        #print(sens_acc[i],sizes[i])\n",
        "        \n",
        "    \n",
        "    TPR = np.zeros(m,dtype=float)\n",
        "    FPR = np.zeros(m,dtype=float)\n",
        "    \n",
        "    accu = 0\n",
        "    n = len(y)\n",
        "    for i in range(n):\n",
        "        if(y.iloc[i,0] == y_pred[i]):\n",
        "            accu = accu+1\n",
        "    \n",
        "    accu = accu/n\n",
        "    \n",
        "    max_tpr = -1 \n",
        "    min_tpr = 2\n",
        "    max_fpr = -1\n",
        "    min_fpr = 2\n",
        "    \n",
        "    for i in range(m):\n",
        "        TPR[i] = sens_stats[2][i]/sens_stats[0][i]\n",
        "        FPR[i] = sens_stats[3][i]/sens_stats[1][i]\n",
        "        if(TPR[i] >= max_tpr):\n",
        "            max_tpr = TPR[i]\n",
        "        if(TPR[i] <= min_tpr):\n",
        "            min_tpr = TPR[i]\n",
        "        if(FPR[i] >= max_fpr):\n",
        "            max_fpr = FPR[i]\n",
        "        if(FPR[i] <= min_fpr):\n",
        "            min_fpr = FPR[i]\n",
        "    \n",
        "    for i in  range(m):\n",
        "        print(\"TPR of the \",i,\"th sensitive groups is\",TPR[i])\n",
        "        \n",
        "    print(\"=====================\")    \n",
        "    for i in  range(m):\n",
        "        print(\"FPR of the \",i,\"th sensitive groups is\",FPR[i])\n",
        "    \n",
        "    print(\"=====================\")\n",
        "    for i in  range(m):    \n",
        "        print(\"Acceptance Rate of the \",i,\"th sensitive groups is\",sens_acc[i])\n",
        "    #print(abs(max_tpr-min_tpr), max_tpr, min_tpr, abs(max_fpr-min_fpr), max_fpr, min_fpr)\n",
        "    DEO = abs(max_tpr-min_tpr) + abs(max_fpr-min_fpr)\n",
        "    \n",
        "    print(\"The Difference of Equalized odds of the classifier is=\",DEO)\n",
        "    print(\"Accuracy of the classifier\",accu)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pulp"
      ],
      "metadata": {
        "id": "SqgJuI3GBcDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh9aP04t6i9D"
      },
      "source": [
        "import pulp as pl\n",
        "solver_list = pl.listSolvers(onlyAvailable=True)\n",
        "print(solver_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accu_all,DP_all,acceptance_rate,alpha_weight = main2(sensitive, y_test, y_test_pred,e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEqBiu9Cou6r",
        "outputId": "54045f7e-1ae0-4acd-9903-a9c258993c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sensitive attribute  1\n",
            "ACTUAL----------total ,accepted, aceeptance rate:\n",
            "618\n",
            "196\n",
            "0.31715210355987056\n",
            "sensitive attribute  2\n",
            "ACTUAL----------total ,accepted, aceeptance rate:\n",
            "11739\n",
            "1190\n",
            "0.10137149672033392\n",
            "sensitive attribute  3\n",
            "ACTUAL----------total ,accepted, aceeptance rate:\n",
            "7468\n",
            "735\n",
            "0.09841992501339046\n",
            "sensitive attribute  4\n",
            "ACTUAL----------total ,accepted, aceeptance rate:\n",
            "3469\n",
            "496\n",
            "0.14298068607667916\n",
            "sensitive attribute  5\n",
            "ACTUAL----------total ,accepted, aceeptance rate:\n",
            "1397\n",
            "149\n",
            "0.1066571224051539\n",
            "sensitive attribute  6\n",
            "ACTUAL----------total ,accepted, aceeptance rate:\n",
            "23\n",
            "6\n",
            "0.2608695652173913\n",
            "data acceptance rates\n",
            "[0.31715210355987056, 0.10137149672033392, 0.09841992501339046, 0.14298068607667916, 0.1066571224051539, 0.2608695652173913]\n",
            "data DP\n",
            "0.21873217854648008\n",
            "sensitive attribute  1\n",
            "prec reca accuracy for each sens\n",
            "0.6783625730994152 0.5918367346938775 0.7815533980582524\n",
            "RanomForest----------total , accepted, aceeptance rate:\n",
            "618\n",
            "171\n",
            "0.2766990291262136\n",
            "sensitive attribute  2\n",
            "prec reca accuracy for each sens\n",
            "0.6682520808561236 0.4722689075630252 0.922736178550132\n",
            "RanomForest----------total , accepted, aceeptance rate:\n",
            "11739\n",
            "841\n",
            "0.07164153675781583\n",
            "sensitive attribute  3\n",
            "prec reca accuracy for each sens\n",
            "0.6909090909090909 0.5170068027210885 0.9297000535618639\n",
            "RanomForest----------total , accepted, aceeptance rate:\n",
            "7468\n",
            "550\n",
            "0.07364756293519015\n",
            "sensitive attribute  4\n",
            "prec reca accuracy for each sens\n",
            "0.6408839779005525 0.46774193548387094 0.8864226001729605\n",
            "RanomForest----------total , accepted, aceeptance rate:\n",
            "3469\n",
            "362\n",
            "0.10435283943499568\n",
            "sensitive attribute  5\n",
            "prec reca accuracy for each sens\n",
            "0.6494845360824743 0.4228187919463087 0.9141016463851109\n",
            "RanomForest----------total , accepted, aceeptance rate:\n",
            "1397\n",
            "97\n",
            "0.06943450250536864\n",
            "sensitive attribute  6\n",
            "prec reca accuracy for each sens\n",
            "1.0 0.5 0.8695652173913043\n",
            "RanomForest----------total , accepted, aceeptance rate:\n",
            "23\n",
            "3\n",
            "0.13043478260869565\n",
            "data acceptance rates\n",
            "[0.2766990291262136, 0.07164153675781583, 0.07364756293519015, 0.10435283943499568, 0.06943450250536864, 0.13043478260869565]\n",
            "data DP\n",
            "0.20726452662084494\n",
            "SVM accuracy--------------------------\n",
            "0.6699604743083004 0.48917748917748916 0.9156753257263089\n",
            "----------------This is for covergence at beta =  0.15  ----------------\n",
            "dimension of data\n",
            "6 12357\n",
            "[  618 11739  7468  3469  1397    23]\n",
            "Optimal\n",
            "objective is:\n",
            "368132.0\n",
            "discripency is:\n",
            "None\n",
            "gamma-epsilon-delta [0.175442, 0.142103, 0.166039, 0.164754, 0.153465, 0.14, 0.104348] 0.5 1\n",
            "<--------------------------------------->\n",
            "TPR of the  0 th sensitive groups is 0.5153061224489796\n",
            "TPR of the  1 th sensitive groups is 0.3949579831932773\n",
            "TPR of the  2 th sensitive groups is 0.43537414965986393\n",
            "TPR of the  3 th sensitive groups is 0.4012096774193548\n",
            "TPR of the  4 th sensitive groups is 0.33557046979865773\n",
            "TPR of the  5 th sensitive groups is 0.3333333333333333\n",
            "=====================\n",
            "FPR of the  0 th sensitive groups is 0.12085308056872038\n",
            "FPR of the  1 th sensitive groups is 0.02038107877523936\n",
            "FPR of the  2 th sensitive groups is 0.020347541957522648\n",
            "FPR of the  3 th sensitive groups is 0.03666330306088127\n",
            "FPR of the  4 th sensitive groups is 0.016025641025641024\n",
            "FPR of the  5 th sensitive groups is 0.0\n",
            "=====================\n",
            "Acceptance Rate of the  0 th sensitive groups is 0.2459546925566343\n",
            "Acceptance Rate of the  1 th sensitive groups is 0.05835250021296533\n",
            "Acceptance Rate of the  2 th sensitive groups is 0.0611944295661489\n",
            "Acceptance Rate of the  3 th sensitive groups is 0.08878639377342173\n",
            "Acceptance Rate of the  4 th sensitive groups is 0.05010737294201861\n",
            "Acceptance Rate of the  5 th sensitive groups is 0.08695652173913043\n",
            "The Difference of Equalized odds of the classifier is= 0.30282586968436664\n",
            "Accuracy of the classifier 0.9125192198753743\n",
            "sensitive attribute  1\n",
            "precision 0.6644736842105263\n",
            "recall 0.5153061224489796\n",
            "FPR 0.12085308056872038\n",
            "TP,FP,TN,FN\n",
            "101 51 371 95\n",
            "sensitive attribute  2\n",
            "precision 0.6861313868613139\n",
            "recall 0.3949579831932773\n",
            "FPR 0.02038107877523936\n",
            "TP,FP,TN,FN\n",
            "470 215 10334 720\n",
            "sensitive attribute  3\n",
            "precision 0.700218818380744\n",
            "recall 0.43537414965986393\n",
            "FPR 0.020347541957522648\n",
            "TP,FP,TN,FN\n",
            "320 137 6596 415\n",
            "sensitive attribute  4\n",
            "precision 0.6461038961038961\n",
            "recall 0.4012096774193548\n",
            "FPR 0.03666330306088127\n",
            "TP,FP,TN,FN\n",
            "199 109 2864 297\n",
            "sensitive attribute  5\n",
            "precision 0.7142857142857143\n",
            "recall 0.33557046979865773\n",
            "FPR 0.016025641025641024\n",
            "TP,FP,TN,FN\n",
            "50 20 1228 99\n",
            "sensitive attribute  6\n",
            "precision 1.0\n",
            "recall 0.3333333333333333\n",
            "FPR 0.0\n",
            "TP,FP,TN,FN\n",
            "2 0 17 4\n",
            "acceptance rates\n",
            "[0.2459546925566343, 0.05835250021296533, 0.0611944295661489, 0.08878639377342173, 0.05010737294201861, 0.08695652173913043]\n",
            "DP\n",
            "0.19584731961461568\n",
            "----------------This is for covergence at beta =  0.18  ----------------\n",
            "dimension of data\n",
            "6 12357\n",
            "[  618 11739  7468  3469  1397    23]\n",
            "Optimal\n",
            "objective is:\n",
            "368132.0\n",
            "discripency is:\n",
            "None\n",
            "gamma-epsilon-delta [0.175442, 0.142103, 0.166039, 0.164754, 0.153465, 0.14, 0.104348] 0.5 1\n",
            "<--------------------------------------->\n",
            "TPR of the  0 th sensitive groups is 0.5153061224489796\n",
            "TPR of the  1 th sensitive groups is 0.3949579831932773\n",
            "TPR of the  2 th sensitive groups is 0.43537414965986393\n",
            "TPR of the  3 th sensitive groups is 0.4012096774193548\n",
            "TPR of the  4 th sensitive groups is 0.33557046979865773\n",
            "TPR of the  5 th sensitive groups is 0.3333333333333333\n",
            "=====================\n",
            "FPR of the  0 th sensitive groups is 0.12085308056872038\n",
            "FPR of the  1 th sensitive groups is 0.02038107877523936\n",
            "FPR of the  2 th sensitive groups is 0.020347541957522648\n",
            "FPR of the  3 th sensitive groups is 0.03666330306088127\n",
            "FPR of the  4 th sensitive groups is 0.016025641025641024\n",
            "FPR of the  5 th sensitive groups is 0.0\n",
            "=====================\n",
            "Acceptance Rate of the  0 th sensitive groups is 0.2459546925566343\n",
            "Acceptance Rate of the  1 th sensitive groups is 0.05835250021296533\n",
            "Acceptance Rate of the  2 th sensitive groups is 0.0611944295661489\n",
            "Acceptance Rate of the  3 th sensitive groups is 0.08878639377342173\n",
            "Acceptance Rate of the  4 th sensitive groups is 0.05010737294201861\n",
            "Acceptance Rate of the  5 th sensitive groups is 0.08695652173913043\n",
            "The Difference of Equalized odds of the classifier is= 0.30282586968436664\n",
            "Accuracy of the classifier 0.9125192198753743\n",
            "sensitive attribute  1\n",
            "precision 0.6644736842105263\n",
            "recall 0.5153061224489796\n",
            "FPR 0.12085308056872038\n",
            "TP,FP,TN,FN\n",
            "101 51 371 95\n",
            "sensitive attribute  2\n",
            "precision 0.6861313868613139\n",
            "recall 0.3949579831932773\n",
            "FPR 0.02038107877523936\n",
            "TP,FP,TN,FN\n",
            "470 215 10334 720\n",
            "sensitive attribute  3\n",
            "precision 0.700218818380744\n",
            "recall 0.43537414965986393\n",
            "FPR 0.020347541957522648\n",
            "TP,FP,TN,FN\n",
            "320 137 6596 415\n",
            "sensitive attribute  4\n",
            "precision 0.6461038961038961\n",
            "recall 0.4012096774193548\n",
            "FPR 0.03666330306088127\n",
            "TP,FP,TN,FN\n",
            "199 109 2864 297\n",
            "sensitive attribute  5\n",
            "precision 0.7142857142857143\n",
            "recall 0.33557046979865773\n",
            "FPR 0.016025641025641024\n",
            "TP,FP,TN,FN\n",
            "50 20 1228 99\n",
            "sensitive attribute  6\n",
            "precision 1.0\n",
            "recall 0.3333333333333333\n",
            "FPR 0.0\n",
            "TP,FP,TN,FN\n",
            "2 0 17 4\n",
            "acceptance rates\n",
            "[0.2459546925566343, 0.05835250021296533, 0.0611944295661489, 0.08878639377342173, 0.05010737294201861, 0.08695652173913043]\n",
            "DP\n",
            "0.19584731961461568\n",
            "precision 0.6821983273596177\n",
            "recall 0.411976911976912\n",
            "TP,FP,TN,FN\n",
            "571 266 10705 815\n",
            "<--------------------------------------->\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5x-gkVy6i9U"
      },
      "source": [
        "# bilal - am_ind asian black other white female male(actual precision sequence)\n",
        "# 6         5          4          2                1              0                  3\n",
        "\n",
        "# ours -s_male, s_female  r_white, r_black, r_asian-pac-islander','r_amer-indian-eskimo','r_other\n",
        "           \n",
        "# beta=[6         5          4          2                1              0                  3]\n",
        "\n",
        "# beta=[beta[6], beta[5],beta[4],beta[2],beta[1],beta[0],beta[3]]\n",
        "\n",
        "\n",
        "#bilal -female male  am_ind asian  black other white (actual acceptance rate sequence)\n",
        "#          0      1     2       3     4      5    6   \n",
        "# ours -s_male, s_female  r_white, r_black, r_asian-pac-islander','r_amer-indian-eskimo', 'r_other\n",
        "           \n",
        "# beta=[1       0        6          4            3                   2                    5]\n",
        "\n",
        "\n",
        "#NG\n",
        "import time\n",
        "#import gurobipy as gp\n",
        "#from gurobipy import GRB\n",
        "import pulp as p \n",
        "def lp_equalized_odds(data1,eps,y_test_pred,e,beta_avg,alpha):\n",
        "    import pulp as p \n",
        "    import math\n",
        "    \n",
        "    \n",
        "    m=data1.shape[0]\n",
        "    n=data1.shape[1]\n",
        "    print('dimension of data')\n",
        "    print(m,n)\n",
        "    \n",
        "        \n",
        "    ############### #  SORTED for ACCURACY ONLY ####\n",
        "    m=6\n",
        "    h1=[]\n",
        "    key1=[]\n",
        "    cost=np.zeros(n,dtype=int)\n",
        "    data2=np.zeros((m,n),dtype=int)\n",
        "    \n",
        "    for i in range(n):\n",
        "            h1.append(e[i][1])\n",
        "            key1.append(i)\n",
        "\n",
        "        \n",
        "#print(hc)\n",
        "#     print(key1)\n",
        "    \n",
        "    for i in range(1,len(h1)):\n",
        "        for j in range(i,0,-1):\n",
        "            var=0\n",
        "            var2=0\n",
        "            if h1[j-1]<h1[j]:\n",
        "                index=j\n",
        "                var=h1[j]\n",
        "                h1[j]=h1[j-1]\n",
        "                h1[j-1]=var\n",
        "\n",
        "                var2=key1[j]\n",
        "                key1[j]=key1[j-1]\n",
        "                key1[j-1]=var2\n",
        "            else:\n",
        "                break\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    for j in range(len(key1)):    \n",
        "         data2[0][key1[j]]=j+1\n",
        "    \n",
        "    for j in range(n):\n",
        "        summ=0\n",
        "        summ=summ+data2[0][j] \n",
        "        cost[j]=summ\n",
        "\n",
        "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
        "    solver = p.getSolver('PULP_CBC_CMD', timeLimit=20)\n",
        "   \n",
        "    \n",
        "#     X=np.zeros(n+1,dtype=p.LpVariable)\n",
        "    X=np.zeros(n+m+1,dtype=p.LpVariable)\n",
        "    Y=np.zeros(m,dtype=p.LpVariable)\n",
        "    \n",
        "    sizes=np.zeros(m,dtype=int)\n",
        "#     report_index(index,data1,e):  \n",
        "    max_size=0\n",
        "    for i in range(m):\n",
        "        count=0\n",
        "        for j in range(n):\n",
        "            if data1[i][j]==1:\n",
        "                count=count+1 \n",
        "        if count>max_size:\n",
        "            max_size=count\n",
        "        sizes[i]=count\n",
        "    print(sizes)    \n",
        "    #############################33\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    ###############################\n",
        "    beta_actual = [0.2452504317789292, 0.05832908813041263, 0.061127282349828, 0.08850338135842399, 0.04727272727272727, 0.043478260869565216]\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    select_sizes=np.zeros(m,dtype=int)\n",
        "   \n",
        "    size_final=np.zeros(m,dtype=int)\n",
        "\n",
        "    for i in range(m):\n",
        "        var1 = str(n+100+i)\n",
        "        Y[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Continuous')\n",
        "    \n",
        "    for i in range(n):\n",
        "        var1=str(i)       \n",
        "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
        "   \n",
        "    X[n]=p.LpVariable(str(n),lowBound=0,upBound=1,cat='Continuous')  \n",
        "\n",
        "    tpr = p.LpVariable(str(n+200),lowBound=0,upBound=1,cat='Continuous')  \n",
        "    fpr = p.LpVariable(str(n+201),lowBound=0,upBound=1,cat='Continuous')  \n",
        "\n",
        "#     for i in range(m):\n",
        "#         k=n+i+1\n",
        "#         var1=str(k)     \n",
        "#         alpha=(((sizes[i])*(sizes[i]+1))/2)\n",
        "#         X[i]=p.LpVariable(var1,lowBound=(((beta*sizes[i])*(beta*sizes[i]+1))/2),upBound=alpha,cat='Continuous')\n",
        "    \n",
        "        \n",
        "#     X[n]=  p.LpVariable(\"z1\",lowBound=0)\n",
        "    #X[n+1]=  p.LpVariable(\"z2\",lowBound=0)\n",
        "  \n",
        "\n",
        "    #########objective function#####################\n",
        "    \n",
        "#     Lp_prob += 2*X[n+1]+10*X[n+2]+9*X[n+3]+3*X[n+4]\n",
        "    #alpha=0.8\n",
        "    #beta_avg = 0.10\n",
        "    Lp_prob+= p.lpSum([(X[j])*cost[j] for j in range(n)]) \n",
        "    #Lp_prob+=1  \n",
        "    \n",
        "    #Lp_prob += Y[0]*sizes[0] + Y[1]*sizes[1] >= p.lpSum([Y[j]*sizes[j] for j in np.arange(2,6)])\n",
        "    #Lp_prob += Y[0]*sizes[0] + Y[1]*sizes[1] <= p.lpSum([Y[j]*sizes[j] for j in np.arange(2,6)])\n",
        "    \n",
        "    ##############constraint#################\n",
        "    #first select the  the number of make female in test data\n",
        "    #then apply the equalized odd constraints assuming \n",
        "    #look at all males which have been predicted positve/and all the females predicted negative\n",
        "    F_test = 0\n",
        "    M_test = 0\n",
        "        \n",
        "    #for i in range(len(y_test)):\n",
        "    #    if(data1[0][i]==1 and y_test.iloc[i]==1):\n",
        "    #        M_test= M_test+1\n",
        "    #    elif(data1[1][i]==1 and y_test.iloc[i]==1):\n",
        "    #        F_test= F_test+1\n",
        "    test_count = np.zeros(m, dtype = int)\n",
        "\n",
        "    for i in range(len(y_test)):\n",
        "      for j in range(m): \n",
        "        if(data1[j][i]==1 and y_test_pred[i]==1):\n",
        "            test_count[j] = test_count[j] +1\n",
        "                \n",
        "    \n",
        "    #Lp_prob += (p.lpSum([(X[j])*(data1[0][j])*y_test_pred[j] for j in range(n) if y_test_pred[j]==1])/M_test) <= (p.lpSum([(X[j])*(data1[1][j])*y_test_pred[j] for j in range(n) if y_test_pred[j]==1])/F_test) + 0.0009\n",
        "    #Lp_prob += (p.lpSum([(X[j])*(data1[0][j])*(1-y_test_pred[j]) for j in range(n) if y_test_pred[j]==0])/(sizes[0]-M_test)) <= (p.lpSum([(X[j])*(data1[1][j])*(1-y_test_pred[j]) for j in range(n) if y_test_pred[j]==0])/(sizes[1]-F_test))+ 0.0009\n",
        "\n",
        "    for i in range(m):   #TPR constraints\n",
        "      Lp_prob += (1/test_count[i])*p.lpSum([(X[j])*(data1[i][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1) ]) >= tpr \n",
        "      Lp_prob += (1/test_count[i])*p.lpSum([(X[j])*(data1[i][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1 )]) <= tpr + 0.1\n",
        "    for i in range(m):    #FPR constraints\n",
        "      Lp_prob += (1/(sizes[i]-test_count[i]))*p.lpSum([(X[j])*(data1[i][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0)]) >= fpr\n",
        "      Lp_prob += (1/(sizes[i]-test_count[i]))*p.lpSum([(X[j])*(data1[i][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0)]) <= fpr + 0.1\n",
        "\n",
        "    #Lp_prob += F_test*p.lpSum([(X[j])*(data1[0][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1) ]) <= M_test*p.lpSum([(X[j])*(data1[1][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1 )]) + 0.004\n",
        "    #Lp_prob += (sizes[1]-F_test)*p.lpSum([(X[j])*(data1[0][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0)]) <= (sizes[0]-M_test)*p.lpSum([(X[j])*(data1[1][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0 )]) + 0.004\n",
        "    \n",
        "\n",
        "\n",
        "    #Lp_prob += F_test*p.lpSum([(X[j])*(data1[0][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1 and y_test.iloc[j]==1) ]) <= M_test*p.lpSum([(X[j])*(data1[1][j])*y_test_pred[j] for j in range(n) if (y_test_pred[j]==1 and y_test.iloc[j]==1)]) + 0.01\n",
        "    #Lp_prob += (sizes[1]-F_test)*p.lpSum([(X[j])*(data1[0][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0 and y_test.iloc[j]==0)]) <= (sizes[0]-M_test)*p.lpSum([(X[j])*(data1[1][j])*(1-y_test_pred[j]) for j in range(n) if (y_test_pred[j]==0 and y_test.iloc[j]==0)]) + 0.01\n",
        "    \n",
        "    #Lp_prob += p.lpSum([(X[j])*(data1[0][j])*y_test.iloc[j] for j in range(n) if y_test.iloc[j]==1])/M_test <= p.lpSum([(X[j])*(data1[1][j])*y_test.iloc[j] for j in range(n) if y_test.iloc[j]==1])/F_test + 0.004\n",
        "    #Lp_prob += (sizes[1]-F_test)*p.lpSum([(X[j])*(data1[0][j])*(1-y_test.iloc[j]) for j in range(n) if y_test.iloc[j]==0])/M_test <= (sizes[0]-M_test)*p.lpSum([(X[j])*(data1[1][j])*(1-y_test.iloc[j]) for j in range(n) if y_test.iloc[j]==0])/F_test + 0.004\n",
        "    \n",
        "    for i in range(m):\n",
        "      #  if i<m:\n",
        "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) >= Y[i]*sizes[i]\n",
        "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) <= (Y[i]+0.1)*sizes[i]\n",
        "    \n",
        "    for i in range(m):\n",
        "        if beta_actual[i] >= beta_avg:\n",
        "            Lp_prob += Y[i] >= (1-alpha)*beta_actual[i] + alpha*beta_avg\n",
        "            Lp_prob += Y[i] <= beta_actual[i]\n",
        "        else:\n",
        "            Lp_prob += Y[i] >= (1-alpha)*beta_actual[i] + alpha*beta_avg\n",
        "            Lp_prob += Y[i] <= beta_avg \n",
        "    \n",
        "           \n",
        "    #Lp_prob+= p.lpSum([(X[j])*cost[j] for j in range(n)])>=100\n",
        "        \n",
        "    #####################################\n",
        "    #solver = p.CPLEX_PY()\n",
        "    #solver.buildSolverModel(Lp_prob)\n",
        "    #Lp_prob.solverModel.parameters.timelimit.set(60)\n",
        "    #solver.callSolver(P)\n",
        "    #status = solver.findSolutionValues(Lp_prob)\n",
        "    #################################################################\n",
        "    status = Lp_prob.solve(solver)   # Solver \n",
        "    print(p.LpStatus[status]) \n",
        "    print(\"objective is:\")        \n",
        "    print(p.value(Lp_prob.objective))\n",
        "    print(\"discripency is:\") \n",
        "    print(p.value(X[n]))\n",
        "    x=np.zeros(n,dtype=float)\n",
        "\n",
        "   # The solution status \n",
        "    Synth1={}\n",
        "    Synth2={}\n",
        "    # # Printing the final solution \n",
        "    for i in range(n):\n",
        "        if(p.value(X[i])==1):\n",
        "            Synth1[i]=1 \n",
        "            Synth2[i]=-1\n",
        "#             if(data1[2][i]==1):\n",
        "#                 print(\"no\")\n",
        "        else:\n",
        "            Synth1[i]=-1\n",
        "            Synth2[i]=1\n",
        "    Synthu1=Synth1  \n",
        "    Synthu2=Synth2  \n",
        "    \n",
        "              \n",
        "    return Synthu1,Synthu2   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX573EbaP-iJ"
      },
      "source": [
        "#without accuracy ---> 2\n",
        "def main2(datax, y_test, y_test_pred,e): \n",
        "        \n",
        "    n=datax.shape[1]\n",
        "    s=datax.shape[0]    \n",
        "    data = np.zeros((s, n), dtype = int)\n",
        "    \n",
        "    r = np.zeros(n, dtype = int) \n",
        "    \n",
        "    for i in range(n):\n",
        "        if int(y_test.iloc[i])==1 :\n",
        "            r[i]=1\n",
        "        else :\n",
        "            r[i]= -1  \n",
        "    \n",
        "    r2 = np.zeros(n, dtype = int) \n",
        "    for i in range(n):\n",
        "        if int(y_test_pred[i])==1 :\n",
        "            r2[i]=1\n",
        "        else :\n",
        "            r2[i]= -1          \n",
        "    ar=[]\n",
        "    \n",
        "    for j in range(s):\n",
        "        print(\"sensitive attribute \",(j+1)) \n",
        "        a=0\n",
        "        b=0\n",
        "        acc1=0\n",
        "        acc2=0\n",
        "        for i in range(n):\n",
        "                data[j][i]= datax.iloc[j,i]\n",
        "                if data[j][i]== 1 :\n",
        "                    a=a+1\n",
        "                    if r[i]==1:\n",
        "                         acc1=acc1+1 \n",
        "\n",
        "        print(\"ACTUAL----------total ,accepted, aceeptance rate:\")             \n",
        "        a1=float(acc1/a)\n",
        "        print(a)\n",
        "        \n",
        "        print(acc1)\n",
        "        print(a1)\n",
        "        ar.append(a1)\n",
        "        \n",
        "    maxi= max(ar)\n",
        "    mini= min(ar)\n",
        "    DP=float(maxi-mini)\n",
        "    print(\"data acceptance rates\")\n",
        "    print(ar)\n",
        "    print(\"data DP\")\n",
        "    print(DP)\n",
        "    \n",
        "    ar=[]\n",
        "    \n",
        "    for j in range(s):\n",
        "        print(\"sensitive attribute \",(j+1)) \n",
        "        a=0\n",
        "        b=0\n",
        "        acc1=0\n",
        "        acc2=0\n",
        "        prec=0\n",
        "        reca=0\n",
        "        accur=0\n",
        "        FP=0\n",
        "        FN=0\n",
        "        TP=0\n",
        "        TN=0\n",
        "        for i in range(n):\n",
        "             if data[j][i]== 1 :\n",
        "                    a=a+1\n",
        "                    if r2[i]==1:\n",
        "                        acc1=acc1+1 \n",
        "                        if r[i]==1:\n",
        "                            TP=TP+1\n",
        "                        else:\n",
        "                             FP=FP+1                \n",
        "                    else:\n",
        "                        if r[i]==1:\n",
        "                            FN=FN+1\n",
        "                        else:\n",
        "                            TN=TN+1    \n",
        "        \n",
        "        print(\"prec reca accuracy for each sens\") \n",
        "        prec= float(TP/(TP+FP))\n",
        "        reca= float(TP/(TP+FN))\n",
        "        accur= float((TP+TN)/a)\n",
        "        print(prec,reca,accur)\n",
        "        \n",
        "        print(\"RanomForest----------total , accepted, aceeptance rate:\")             \n",
        "        \n",
        "        a1=float(acc1/a)\n",
        "        print(a)\n",
        "        \n",
        "        print(acc1)\n",
        "        print(a1)\n",
        "        ar.append(a1)\n",
        "        \n",
        "    maxi= max(ar)\n",
        "    mini= min(ar)\n",
        "    DP=float(maxi-mini)\n",
        "    print(\"data acceptance rates\")\n",
        "    print(ar)\n",
        "    print(\"data DP\")\n",
        "    print(DP) \n",
        "    \n",
        "    print(\"SVM accuracy--------------------------\")\n",
        "    prec=0\n",
        "    reca=0\n",
        "    accur=0\n",
        "    FP=0\n",
        "    FN=0\n",
        "    TP=0\n",
        "    TN=0\n",
        "    for i in range(n):\n",
        "            if r2[i]==1:\n",
        "                acc1=acc1+1 \n",
        "                if r[i]==1:\n",
        "                    TP=TP+1\n",
        "                else:\n",
        "                     FP=FP+1                \n",
        "            else:\n",
        "                if r[i]==1:\n",
        "                     FN=FN+1\n",
        "                else:\n",
        "                     TN=TN+1    \n",
        "\n",
        "        \n",
        "    prec= float(TP/(TP+FP))\n",
        "    reca= float(TP/(TP+FN))\n",
        "    accur= float((TP+TN)/n)\n",
        "    print(prec,reca,accur)\n",
        "    \n",
        "    \n",
        "#     delta1=[.70,.75,.80,.85,.90,.95]\n",
        "    #gamma=.05,.06,.07\n",
        "    #delta1=[.80,.85,.90,.95]\n",
        "# (for reproducibility)  \n",
        "\n",
        "# delta1=[.8], gama=[.1], epsilon=[.05]  \n",
        "# delta1=[.8], gama=[.15], epsilon=[.01]\n",
        " \n",
        "#     delta1=np.arange(1,.79,-.01)\n",
        "    delta=1\n",
        "#     gama=[.05,.1,.15,.2,.25]\n",
        "#     epsilon=[.01,.02,.05,.1,.15,.20,.25,.30,.35,.40,.50]\n",
        "\n",
        "#ADULT ZAFAR =? epsilon=[0.088 ,0.1656, 0.168,  0.211, 0.251 ] \n",
        " \n",
        "#agarwal=> epsilon=[ 0.071, 0.1271, 0.2437, 0.27 ]\n",
        " \n",
        "\n",
        "    #gama=[0.0869, 0.0521,0.0782, 0.0608,0.0434, 0.1,0.069,0.0434,0.034]\n",
        "    epsilon=[.5]\n",
        "    beta_converge = [0.15,0.18]\n",
        "    alpha = [0]\n",
        "    \n",
        "    zero_one = np.zeros(n, dtype = int) \n",
        "    \n",
        "    fi= np.zeros(n,dtype=int) \n",
        "#     for delta in delta1:\n",
        "    #4 gamma=[0.175442,    0.142103, 0.166039,    0.164754,  0.153465,    0.14,  0.104348   ]\n",
        "    #lp_equalized_odds_no_beta(data1,eps,y_test,e,beta_avg,alpha)\n",
        "    #1 gamma=[0.259147,   0.0730028, 0.210139, 0.0893443, 0.306931, 0.0933333,  0.0347826]\n",
        "    #gamma=[0.196178,0.126722,   0.179654, 0.140164,     0.153465,   0.133333,  0.0695652]\n",
        "\n",
        "  \n",
        "    gamma = [0.175442,    0.142103, 0.166039,    0.164754,  0.153465,    0.14,  0.104348 ]\n",
        "    for eps in epsilon:\n",
        "        for beta_avg in beta_converge:\n",
        "            print(\"----------------This is for covergence at beta = \",beta_avg, \" ----------------\")\n",
        "            for a in alpha:\n",
        "                u1,u2=lp_equalized_odds(data,eps,y_test_pred,e,beta_avg,a)\n",
        "                #######################Disp_impact#######################  \n",
        "                print(\"gamma-epsilon-delta\",gamma,eps,delta)\n",
        "                accu_all=[]\n",
        "                DP_all=[]\n",
        "                precision_all=[]\n",
        "                recall_all=[]\n",
        "                acceptance_rate=np.zeros((7,28),dtype=float)\n",
        "                count=0\n",
        "                print(\"<--------------------------------------->\")\n",
        "            #        print(\"iteration t\",t)\n",
        "            #                 for alpha in np.arange(0,1.05,0.05):\n",
        "            #                     print(\"alpha: \",alpha)\n",
        "            #                     for i in range(n):\n",
        "\n",
        "            #                         z=random()\n",
        "            #                         if z < alpha:\n",
        "            #                                fi[i]= u1[i] \n",
        "\n",
        "            #                         else:\n",
        "            #                                fi[i]= r2[i]\n",
        "                \n",
        "                for i in range(n):\n",
        "                    fi[i] = u1[i]\n",
        "                    if (fi[i]==1):\n",
        "                        zero_one[i] = 1\n",
        "                    else:\n",
        "                        zero_one[i] = 0\n",
        "                ar=[]\n",
        "                find_eo_stats_multiple(y_test,zero_one)\n",
        "\n",
        "\n",
        "                for j in range(s):\n",
        "                    print(\"sensitive attribute \",(j+1)) \n",
        "\n",
        "                    TP=0\n",
        "                    FP=0\n",
        "                    FN=0\n",
        "                    TN=0\n",
        "                    precision=0\n",
        "                    recall=0\n",
        "                    for i in range(n):\n",
        "                         if data[j][i]== 1 :                        \n",
        "                            if fi[i]==1 and r[i]==1:\n",
        "                                TP=TP+1\n",
        "                            if fi[i]==1 and r[i]==-1:\n",
        "                                FP=FP+1 \n",
        "                            if fi[i]==-1 and r[i]==1:\n",
        "                                FN=FN+1\n",
        "                            if fi[i]==-1 and r[i]==-1:\n",
        "                                TN=TN+1    \n",
        "                    if TP+FP !=0:\n",
        "                        precision=float(TP/(TP+FP))\n",
        "                    print(\"precision\",precision)\n",
        "                    if TP+FN !=0:    \n",
        "                        recall=float(TP/(TP+FN))\n",
        "                    print(\"recall\",recall)\n",
        "                    if FP+TN !=0:\n",
        "                        fpr = float(FP/(FP+TN))\n",
        "                    print(\"FPR\", fpr)    \n",
        "                    print(\"TP,FP,TN,FN\")\n",
        "                    print(TP,FP,TN,FN)\n",
        "                    a=0\n",
        "                    b=0\n",
        "                    acc1=0\n",
        "                    acc2=0\n",
        "                    for i in range(n):\n",
        "                            if data[j][i]== 1 :\n",
        "                                a=a+1\n",
        "                                if fi[i]==1:\n",
        "                                     acc1=acc1+1 \n",
        "\n",
        "            #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
        "                    a1=float(acc1/a)\n",
        "\n",
        "\n",
        "\n",
        "            #                         print(a)\n",
        "            #                         print(acc1)\n",
        "            #                         print(a1)\n",
        "                    ar.append(a1)\n",
        "\n",
        "                count = count+1\n",
        "                maxi=max(ar)\n",
        "                mini= min(ar)\n",
        "                DP=float(maxi-mini)\n",
        "                print(\"acceptance rates\")\n",
        "                print(ar)\n",
        "                print(\"DP\")\n",
        "                print(DP)\n",
        "                f_acc=0\n",
        "                for i in range(n):\n",
        "                     if fi[i] == r[i]:\n",
        "                            f_acc=f_acc+1\n",
        "                f_acc_l=float((f_acc*100)/n) \n",
        "\n",
        "#######################################################################33   \n",
        "\n",
        "#                         print(\"sensitive attribute \",(j+1)) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        TP=0\n",
        "        FP=0\n",
        "        FN=0\n",
        "        TN=0\n",
        "        precision=0\n",
        "        recall=0\n",
        "        for i in range(n):\n",
        "                if fi[i]==1 and r[i]==1:\n",
        "                    TP=TP+1\n",
        "                if fi[i]==1 and r[i]==-1:\n",
        "                    FP=FP+1 \n",
        "                if fi[i]==-1 and r[i]==1:\n",
        "                    FN=FN+1\n",
        "                if fi[i]==-1 and r[i]==-1:\n",
        "                    TN=TN+1    \n",
        "\n",
        "        if TP+FP!=0:\n",
        "            precision=float(TP/(TP+FP))\n",
        "        print(\"precision\",precision)\n",
        "        if TP+FN!=0:\n",
        "            recall=float(TP/(TP+FN))    \n",
        "\n",
        "        print(\"recall\",recall)\n",
        "        \n",
        "        accu = float((TP + TN)/n)\n",
        "        print(\"TP,FP,TN,FN\")\n",
        "        print(TP,FP,TN,FN)\n",
        "#       print(\"total ,fair accepted, aceeptance rate:\")             \n",
        "        a1=float(acc1/a)\n",
        "\n",
        "\n",
        "    print(\"<--------------------------------------->\")\n",
        "    alpha_weight=np.arange(0,1.05,.05)        \n",
        "    return accu_all,DP_all,acceptance_rate,alpha_weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xaBSTbp6i_L"
      },
      "source": [
        "pip install pulp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuwPOsD36jBf"
      },
      "source": [
        "#without accuracy ---> 2\n",
        "def main2(datax, y_test, y_test_pred,e): \n",
        "        \n",
        "    n=datax.shape[1]\n",
        "    s=datax.shape[0]    \n",
        "    data = np.zeros((s, n), dtype = int)\n",
        "    \n",
        "    r = np.zeros(n, dtype = int) \n",
        "    \n",
        "    for i in range(n):\n",
        "        if int(y_test.iloc[i])==1 :\n",
        "            r[i]=1\n",
        "        else :\n",
        "            r[i]= -1  \n",
        "    \n",
        "    r2 = np.zeros(n, dtype = int) \n",
        "    for i in range(n):\n",
        "        if int(y_test_pred[i])==1 :\n",
        "            r2[i]=1\n",
        "        else :\n",
        "            r2[i]= -1          \n",
        "    ar=[]\n",
        "    \n",
        "    for j in range(s):\n",
        "        print(\"sensitive attribute \",(j+1)) \n",
        "        a=0\n",
        "        b=0\n",
        "        acc1=0\n",
        "        acc2=0\n",
        "        for i in range(n):\n",
        "                data[j][i]= datax.iloc[j,i]\n",
        "                if data[j][i]== 1 :\n",
        "                    a=a+1\n",
        "                    if r[i]==1:\n",
        "                         acc1=acc1+1 \n",
        "\n",
        "        print(\"ACTUAL----------total ,accepted, aceeptance rate:\")             \n",
        "        a1=float(acc1/a)\n",
        "        print(a)\n",
        "        \n",
        "        print(acc1)\n",
        "        print(a1)\n",
        "        ar.append(a1)\n",
        "        \n",
        "    maxi= max(ar)\n",
        "    mini= min(ar)\n",
        "    DP=float(maxi-mini)\n",
        "    print(\"data acceptance rates\")\n",
        "    print(ar)\n",
        "    print(\"data DP\")\n",
        "    print(DP)\n",
        "    \n",
        "    ar=[]\n",
        "    \n",
        "    for j in range(s):\n",
        "        print(\"sensitive attribute \",(j+1)) \n",
        "        a=0\n",
        "        b=0\n",
        "        acc1=0\n",
        "        acc2=0\n",
        "        prec=0\n",
        "        reca=0\n",
        "        accur=0\n",
        "        FP=0\n",
        "        FN=0\n",
        "        TP=0\n",
        "        TN=0\n",
        "        for i in range(n):\n",
        "             if data[j][i]== 1 :\n",
        "                    a=a+1\n",
        "                    if r2[i]==1:\n",
        "                        acc1=acc1+1 \n",
        "                        if r[i]==1:\n",
        "                            TP=TP+1\n",
        "                        else:\n",
        "                             FP=FP+1                \n",
        "                    else:\n",
        "                        if r[i]==1:\n",
        "                            FN=FN+1\n",
        "                        else:\n",
        "                            TN=TN+1    \n",
        "        \n",
        "        print(\"prec reca accuracy for each sens\") \n",
        "        prec= float(TP/(TP+FP))\n",
        "        reca= float(TP/(TP+FN))\n",
        "        accur= float((TP+TN)/a)\n",
        "        print(prec,reca,accur)\n",
        "        \n",
        "        print(\"SVM----------total , accepted, aceeptance rate:\")             \n",
        "        \n",
        "        a1=float(acc1/a)\n",
        "        print(a)\n",
        "        \n",
        "        print(acc1)\n",
        "        print(a1)\n",
        "        ar.append(a1)\n",
        "        \n",
        "    maxi= max(ar)\n",
        "    mini= min(ar)\n",
        "    DP=float(maxi-mini)\n",
        "    print(\"data acceptance rates\")\n",
        "    print(ar)\n",
        "    print(\"data DP\")\n",
        "    print(DP) \n",
        "    \n",
        "    print(\"SVM accuracy--------------------------\")\n",
        "    prec=0\n",
        "    reca=0\n",
        "    accur=0\n",
        "    FP=0\n",
        "    FN=0\n",
        "    TP=0\n",
        "    TN=0\n",
        "    for i in range(n):\n",
        "            if r2[i]==1:\n",
        "                acc1=acc1+1 \n",
        "                if r[i]==1:\n",
        "                    TP=TP+1\n",
        "                else:\n",
        "                     FP=FP+1                \n",
        "            else:\n",
        "                if r[i]==1:\n",
        "                     FN=FN+1\n",
        "                else:\n",
        "                     TN=TN+1    \n",
        "\n",
        "        \n",
        "    prec= float(TP/(TP+FP))\n",
        "    reca= float(TP/(TP+FN))\n",
        "    accur= float((TP+TN)/n)\n",
        "    print(prec,reca,accur)\n",
        "    \n",
        "    \n",
        "#     delta1=[.70,.75,.80,.85,.90,.95]\n",
        "    #gamma=.05,.06,.07\n",
        "    #delta1=[.80,.85,.90,.95]\n",
        "# (for reproducibility)  \n",
        "\n",
        "# delta1=[.8], gama=[.1], epsilon=[.05]  \n",
        "# delta1=[.8], gama=[.15], epsilon=[.01]\n",
        " \n",
        "#     delta1=np.arange(1,.79,-.01)\n",
        "    delta=1\n",
        "#     gama=[.05,.1,.15,.2,.25]\n",
        "#     epsilon=[.01,.02,.05,.1,.15,.20,.25,.30,.35,.40,.50]\n",
        "\n",
        "#ADULT ZAFAR =? epsilon=[0.088 ,0.1656, 0.168,  0.211, 0.251 ] \n",
        " \n",
        "#agarwal=> epsilon=[ 0.071, 0.1271, 0.2437, 0.27 ]\n",
        " \n",
        "\n",
        "    #gama=[0.0869, 0.0521,0.0782, 0.0608,0.0434, 0.1,0.069,0.0434,0.034]\n",
        "    epsilon=[.01]\n",
        "    beta_converge = [0.15,0.20]\n",
        "    alpha = [0,0.06,0.062,0.065,0.07,0.8]\n",
        "    \n",
        "    zero_one = np.zeros(n, dtype = int) \n",
        "    \n",
        "    fi= np.zeros(n,dtype=int) \n",
        "#     for delta in delta1:\n",
        "    #4 gamma=[0.175442,    0.142103, 0.166039,    0.164754,  0.153465,    0.14,  0.104348   ]\n",
        "    #lp_equalized_odds_no_beta(data1,eps,y_test,e,beta_avg,alpha)\n",
        "    #1 gamma=[0.259147,   0.0730028, 0.210139, 0.0893443, 0.306931, 0.0933333,  0.0347826]\n",
        "    #gamma=[0.196178,0.126722,   0.179654, 0.140164,     0.153465,   0.133333,  0.0695652]\n",
        "\n",
        "  \n",
        "    gamma = [0.175442,    0.142103, 0.166039,    0.164754,  0.153465,    0.14,  0.104348 ]\n",
        "    for eps in epsilon:\n",
        "        for beta_avg in beta_converge:\n",
        "            print(\"----------------This is for covergence at beta = \",beta_avg, \" ----------------\")\n",
        "            for a in alpha:\n",
        "                u1,u2=lp_equalized_odds(data,eps,y_test_pred,e,beta_avg,a)\n",
        "                #######################Disp_impact#######################  \n",
        "                print(\"gamma-epsilon-delta\",gamma,eps,delta)\n",
        "                accu_all=[]\n",
        "                DP_all=[]\n",
        "                precision_all=[]\n",
        "                recall_all=[]\n",
        "                acceptance_rate=np.zeros((7,28),dtype=float)\n",
        "                count=0\n",
        "                print(\"<--------------------------------------->\")\n",
        "            #        print(\"iteration t\",t)\n",
        "            #                 for alpha in np.arange(0,1.05,0.05):\n",
        "            #                     print(\"alpha: \",alpha)\n",
        "            #                     for i in range(n):\n",
        "\n",
        "            #                         z=random()\n",
        "            #                         if z < alpha:\n",
        "            #                                fi[i]= u1[i] \n",
        "\n",
        "            #                         else:\n",
        "            #                                fi[i]= r2[i]\n",
        "                \n",
        "                for i in range(n):\n",
        "                    fi[i] = u1[i]\n",
        "                    if (fi[i]==1):\n",
        "                        zero_one[i] = 1\n",
        "                    else:\n",
        "                        zero_one[i] = 0\n",
        "                ar=[]\n",
        "                find_eo_stats(y_test,zero_one)\n",
        "                for j in range(s):\n",
        "                    print(\"sensitive attribute \",(j+1)) \n",
        "\n",
        "                    TP=0\n",
        "                    FP=0\n",
        "                    FN=0\n",
        "                    TN=0\n",
        "                    precision=0\n",
        "                    recall=0\n",
        "                    for i in range(n):\n",
        "                         if data[j][i]== 1 :                        \n",
        "                            if fi[i]==1 and r[i]==1:\n",
        "                                TP=TP+1\n",
        "                            if fi[i]==1 and r[i]==-1:\n",
        "                                FP=FP+1 \n",
        "                            if fi[i]==-1 and r[i]==1:\n",
        "                                FN=FN+1\n",
        "                            if fi[i]==-1 and r[i]==-1:\n",
        "                                TN=TN+1    \n",
        "                    if TP+FP !=0:\n",
        "                        precision=float(TP/(TP+FP))\n",
        "                    print(\"precision\",precision)\n",
        "                    if TP+FN !=0:    \n",
        "                        recall=float(TP/(TP+FN))\n",
        "                    print(\"recall\",recall)\n",
        "                    if FP+TN !=0:\n",
        "                        fpr = float(FP/(FP+TN))\n",
        "                    print(\"FPR\", fpr)    \n",
        "                    print(\"TP,FP,TN,FN\")\n",
        "                    print(TP,FP,TN,FN)\n",
        "                    a=0\n",
        "                    b=0\n",
        "                    acc1=0\n",
        "                    acc2=0\n",
        "                    for i in range(n):\n",
        "                            if data[j][i]== 1 :\n",
        "                                a=a+1\n",
        "                                if fi[i]==1:\n",
        "                                     acc1=acc1+1 \n",
        "\n",
        "            #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
        "                    a1=float(acc1/a)\n",
        "\n",
        "\n",
        "\n",
        "            #                         print(a)\n",
        "            #                         print(acc1)\n",
        "            #                         print(a1)\n",
        "                    ar.append(a1)\n",
        "\n",
        "                count = count+1\n",
        "                maxi=max(ar)\n",
        "                mini= min(ar)\n",
        "                DP=float(maxi-mini)\n",
        "                print(\"acceptance rates\")\n",
        "                print(ar)\n",
        "                print(\"DP\")\n",
        "                print(DP)\n",
        "                f_acc=0\n",
        "                for i in range(n):\n",
        "                     if fi[i] == r[i]:\n",
        "                            f_acc=f_acc+1\n",
        "                f_acc_l=float((f_acc*100)/n) \n",
        "\n",
        "#######################################################################33   \n",
        "\n",
        "#                         print(\"sensitive attribute \",(j+1)) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        TP=0\n",
        "        FP=0\n",
        "        FN=0\n",
        "        TN=0\n",
        "        precision=0\n",
        "        recall=0\n",
        "        for i in range(n):\n",
        "                if fi[i]==1 and r[i]==1:\n",
        "                    TP=TP+1\n",
        "                if fi[i]==1 and r[i]==-1:\n",
        "                    FP=FP+1 \n",
        "                if fi[i]==-1 and r[i]==1:\n",
        "                    FN=FN+1\n",
        "                if fi[i]==-1 and r[i]==-1:\n",
        "                    TN=TN+1    \n",
        "\n",
        "        if TP+FP!=0:\n",
        "            precision=float(TP/(TP+FP))\n",
        "        print(\"precision\",precision)\n",
        "        if TP+FN!=0:\n",
        "            recall=float(TP/(TP+FN))    \n",
        "\n",
        "        print(\"recall\",recall)\n",
        "        \n",
        "        accu = float((TP + TN)/n)\n",
        "        print(\"TP,FP,TN,FN\")\n",
        "        print(TP,FP,TN,FN)\n",
        "#       print(\"total ,fair accepted, aceeptance rate:\")             \n",
        "        a1=float(acc1/a)\n",
        "\n",
        "\n",
        "    print(\"<--------------------------------------->\")\n",
        "    alpha_weight=np.arange(0,1.05,.05)        \n",
        "    return accu_all,DP_all,acceptance_rate,alpha_weight"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}